{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdt.transformers import ClusterBasedNormalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('insurance_claims.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_bind_date</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>policy_csl</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip</th>\n",
       "      <th>...</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_make</th>\n",
       "      <th>auto_model</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>fraud_reported</th>\n",
       "      <th>_c39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>521585</td>\n",
       "      <td>2014-10-17</td>\n",
       "      <td>OH</td>\n",
       "      <td>250/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406.91</td>\n",
       "      <td>0</td>\n",
       "      <td>466132</td>\n",
       "      <td>...</td>\n",
       "      <td>YES</td>\n",
       "      <td>71610</td>\n",
       "      <td>6510</td>\n",
       "      <td>13020</td>\n",
       "      <td>52080</td>\n",
       "      <td>Saab</td>\n",
       "      <td>92x</td>\n",
       "      <td>2004</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>IN</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>468176</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>5070</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>3510</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>E400</td>\n",
       "      <td>2007</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>687698</td>\n",
       "      <td>2000-09-06</td>\n",
       "      <td>OH</td>\n",
       "      <td>100/300</td>\n",
       "      <td>2000</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>5000000</td>\n",
       "      <td>430632</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>34650</td>\n",
       "      <td>7700</td>\n",
       "      <td>3850</td>\n",
       "      <td>23100</td>\n",
       "      <td>Dodge</td>\n",
       "      <td>RAM</td>\n",
       "      <td>2007</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>227811</td>\n",
       "      <td>1990-05-25</td>\n",
       "      <td>IL</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>6000000</td>\n",
       "      <td>608117</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>63400</td>\n",
       "      <td>6340</td>\n",
       "      <td>6340</td>\n",
       "      <td>50720</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Tahoe</td>\n",
       "      <td>2014</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>44</td>\n",
       "      <td>367455</td>\n",
       "      <td>2014-06-06</td>\n",
       "      <td>IL</td>\n",
       "      <td>500/1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1583.91</td>\n",
       "      <td>6000000</td>\n",
       "      <td>610706</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>6500</td>\n",
       "      <td>1300</td>\n",
       "      <td>650</td>\n",
       "      <td>4550</td>\n",
       "      <td>Accura</td>\n",
       "      <td>RSX</td>\n",
       "      <td>2009</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   months_as_customer  age  policy_number policy_bind_date policy_state  \\\n",
       "0                 328   48         521585       2014-10-17           OH   \n",
       "1                 228   42         342868       2006-06-27           IN   \n",
       "2                 134   29         687698       2000-09-06           OH   \n",
       "3                 256   41         227811       1990-05-25           IL   \n",
       "4                 228   44         367455       2014-06-06           IL   \n",
       "\n",
       "  policy_csl  policy_deductable  policy_annual_premium  umbrella_limit  \\\n",
       "0    250/500               1000                1406.91               0   \n",
       "1    250/500               2000                1197.22         5000000   \n",
       "2    100/300               2000                1413.14         5000000   \n",
       "3    250/500               2000                1415.74         6000000   \n",
       "4   500/1000               1000                1583.91         6000000   \n",
       "\n",
       "   insured_zip  ... police_report_available total_claim_amount injury_claim  \\\n",
       "0       466132  ...                     YES              71610         6510   \n",
       "1       468176  ...                       ?               5070          780   \n",
       "2       430632  ...                      NO              34650         7700   \n",
       "3       608117  ...                      NO              63400         6340   \n",
       "4       610706  ...                      NO               6500         1300   \n",
       "\n",
       "  property_claim vehicle_claim  auto_make  auto_model auto_year  \\\n",
       "0          13020         52080       Saab         92x      2004   \n",
       "1            780          3510   Mercedes        E400      2007   \n",
       "2           3850         23100      Dodge         RAM      2007   \n",
       "3           6340         50720  Chevrolet       Tahoe      2014   \n",
       "4            650          4550     Accura         RSX      2009   \n",
       "\n",
       "  fraud_reported _c39  \n",
       "0              Y  NaN  \n",
       "1              Y  NaN  \n",
       "2              N  NaN  \n",
       "3              Y  NaN  \n",
       "4              N  NaN  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transform continuous columns\n",
    "* genarete named tuple containing information of a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "SpanInfo = namedtuple('SpanInfo', ['dim', 'activation_fn'])\n",
    "ColumnTransformInfo = namedtuple(\n",
    "    'ColumnTransformInfo', [\n",
    "        'column_name', 'column_type', 'transform', 'output_info', 'output_dimensions'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fit_continuous(data):\n",
    "        \"\"\"Train Bayesian GMM for continuous columns.\n",
    "        Args:\n",
    "            data (pd.DataFrame):\n",
    "                A dataframe containing a column.\n",
    "        Returns:\n",
    "            namedtuple:\n",
    "                A ``ColumnTransformInfo`` object.\n",
    "        \"\"\"\n",
    "        column_name = data.columns[0]\n",
    "        gm = ClusterBasedNormalizer(model_missing_values=True, max_clusters=min(len(data), 10))\n",
    "        gm.fit(data, column_name)\n",
    "        num_components = sum(gm.valid_component_indicator)\n",
    "\n",
    "        return ColumnTransformInfo(\n",
    "            column_name=column_name, column_type='continuous', transform=gm,\n",
    "            output_info=[SpanInfo(1, 'tanh'), SpanInfo(num_components, 'softmax')],\n",
    "            output_dimensions=1 + num_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformInfo(column_name='total_claim_amount', column_type='continuous', transform=ClusterBasedNormalizer(model_missing_values=True), output_info=[SpanInfo(dim=1, activation_fn='tanh'), SpanInfo(dim=6, activation_fn='softmax')], output_dimensions=7)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data (pd.DataFrame):A dataframe containing a column.\n",
    "data = df[['total_claim_amount']]\n",
    "_fit_continuous(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame, 1000)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data (pd.DataFrame):A dataframe containing a column.\n",
    "data = df[['total_claim_amount']]\n",
    "type(data), len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'total_claim_amount'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_name = data.columns[0]\n",
    "column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = ClusterBasedNormalizer(model_missing_values=True, max_clusters=min(len(data), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.fit(data, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['total_claim_amount.normalized', 'total_claim_amount.component'],\n",
       " ['total_claim_amount'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm.get_output_columns(), gm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm.valid_component_indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_components = sum(gm.valid_component_indicator)\n",
    "num_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_claim_amount.normalized</th>\n",
       "      <th>total_claim_amount.component</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.043611</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.037903</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.472925</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.126648</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041942</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.420494</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.570246</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.193973</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-0.308193</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.038461</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     total_claim_amount.normalized  total_claim_amount.component\n",
       "0                         0.043611                           2.0\n",
       "1                        -0.037903                           0.0\n",
       "2                        -0.472925                           1.0\n",
       "3                         0.126648                           4.0\n",
       "4                         0.041942                           0.0\n",
       "..                             ...                           ...\n",
       "995                       0.420494                           1.0\n",
       "996                       0.570246                           2.0\n",
       "997                       0.193973                           3.0\n",
       "998                      -0.308193                           2.0\n",
       "999                      -0.038461                           0.0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data = gm.transform(data)\n",
    "transformed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transform discrete columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdt.transformers import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fit_discrete(data):\n",
    "        \"\"\"Fit one hot encoder for discrete column.\n",
    "        Args:\n",
    "            data (pd.DataFrame):\n",
    "                A dataframe containing a column.\n",
    "        Returns:\n",
    "            namedtuple:\n",
    "                A ``ColumnTransformInfo`` object.\n",
    "        \"\"\"\n",
    "        column_name = data.columns[0]\n",
    "        ohe = OneHotEncoder()\n",
    "        ohe.fit(data, column_name)\n",
    "        num_categories = len(ohe.dummies)\n",
    "\n",
    "        return ColumnTransformInfo(\n",
    "            column_name=column_name, column_type='discrete', transform=ohe,\n",
    "            output_info=[SpanInfo(num_categories, 'softmax')],\n",
    "            output_dimensions=num_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['auto_make']]\n",
    "column_name = data.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "ohe.fit(data, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Saab',\n",
       " 'Mercedes',\n",
       " 'Dodge',\n",
       " 'Chevrolet',\n",
       " 'Accura',\n",
       " 'Nissan',\n",
       " 'Audi',\n",
       " 'Toyota',\n",
       " 'Ford',\n",
       " 'Suburu',\n",
       " 'BMW',\n",
       " 'Jeep',\n",
       " 'Honda',\n",
       " 'Volkswagen']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_categories = len(ohe.dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auto_make.value0</th>\n",
       "      <th>auto_make.value1</th>\n",
       "      <th>auto_make.value2</th>\n",
       "      <th>auto_make.value3</th>\n",
       "      <th>auto_make.value4</th>\n",
       "      <th>auto_make.value5</th>\n",
       "      <th>auto_make.value6</th>\n",
       "      <th>auto_make.value7</th>\n",
       "      <th>auto_make.value8</th>\n",
       "      <th>auto_make.value9</th>\n",
       "      <th>auto_make.value10</th>\n",
       "      <th>auto_make.value11</th>\n",
       "      <th>auto_make.value12</th>\n",
       "      <th>auto_make.value13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     auto_make.value0  auto_make.value1  auto_make.value2  auto_make.value3  \\\n",
       "0                   1                 0                 0                 0   \n",
       "1                   0                 1                 0                 0   \n",
       "2                   0                 0                 1                 0   \n",
       "3                   0                 0                 0                 1   \n",
       "4                   0                 0                 0                 0   \n",
       "..                ...               ...               ...               ...   \n",
       "995                 0                 0                 0                 0   \n",
       "996                 0                 0                 0                 0   \n",
       "997                 0                 0                 0                 0   \n",
       "998                 0                 0                 0                 0   \n",
       "999                 0                 1                 0                 0   \n",
       "\n",
       "     auto_make.value4  auto_make.value5  auto_make.value6  auto_make.value7  \\\n",
       "0                   0                 0                 0                 0   \n",
       "1                   0                 0                 0                 0   \n",
       "2                   0                 0                 0                 0   \n",
       "3                   0                 0                 0                 0   \n",
       "4                   1                 0                 0                 0   \n",
       "..                ...               ...               ...               ...   \n",
       "995                 0                 0                 0                 0   \n",
       "996                 0                 0                 0                 0   \n",
       "997                 0                 0                 0                 0   \n",
       "998                 0                 0                 1                 0   \n",
       "999                 0                 0                 0                 0   \n",
       "\n",
       "     auto_make.value8  auto_make.value9  auto_make.value10  auto_make.value11  \\\n",
       "0                   0                 0                  0                  0   \n",
       "1                   0                 0                  0                  0   \n",
       "2                   0                 0                  0                  0   \n",
       "3                   0                 0                  0                  0   \n",
       "4                   0                 0                  0                  0   \n",
       "..                ...               ...                ...                ...   \n",
       "995                 0                 0                  0                  0   \n",
       "996                 0                 0                  0                  0   \n",
       "997                 0                 1                  0                  0   \n",
       "998                 0                 0                  0                  0   \n",
       "999                 0                 0                  0                  0   \n",
       "\n",
       "     auto_make.value12  auto_make.value13  \n",
       "0                    0                  0  \n",
       "1                    0                  0  \n",
       "2                    0                  0  \n",
       "3                    0                  0  \n",
       "4                    0                  0  \n",
       "..                 ...                ...  \n",
       "995                  1                  0  \n",
       "996                  0                  1  \n",
       "997                  0                  0  \n",
       "998                  0                  0  \n",
       "999                  0                  0  \n",
       "\n",
       "[1000 rows x 14 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data = ohe.transform(data)\n",
    "transformed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit function\n",
    "* aggregate the transform information(namedtuples) of all columns in raw data in `column_transform_info_list`, also the output information of all columns(including output dimension and activation function_ as namedtuples ) are stored in `output_info_list`. also the output dimension of transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(raw_data, discrete_columns=()):\n",
    "        \"\"\"Fit the ``DataTransformer``.\n",
    "        Fits a ``ClusterBasedNormalizer`` for continuous columns and a\n",
    "        ``OneHotEncoder`` for discrete columns.\n",
    "        This step also counts the #columns in matrix data and span information.\n",
    "        \"\"\"\n",
    "        output_info_list = []\n",
    "        output_dimensions = 0\n",
    "        dataframe = True\n",
    "\n",
    "        column_raw_dtypes = raw_data.infer_objects().dtypes\n",
    "        column_transform_info_list = []\n",
    "        for column_name in raw_data.columns:\n",
    "            if column_name in discrete_columns:\n",
    "                column_transform_info = _fit_discrete(raw_data[[column_name]])\n",
    "            else:\n",
    "                column_transform_info = _fit_continuous(raw_data[[column_name]])\n",
    "\n",
    "            output_info_list.append(column_transform_info.output_info)\n",
    "            output_dimensions += column_transform_info.output_dimensions\n",
    "            column_transform_info_list.append(column_transform_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[['injury_claim', 'property_claim', 'vehicle_claim', 'auto_make', 'auto_model', 'auto_year']]\n",
    "raw_data = df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_raw_dtypes = raw_data.infer_objects().dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transform_info_list = []\n",
    "discrete_columns = ['auto_make', 'auto_model', 'auto_year']\n",
    "output_info_list = []\n",
    "output_dimensions = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_name in raw_data.columns:\n",
    "    if column_name in discrete_columns:\n",
    "        column_transform_info = _fit_discrete(raw_data[[column_name]])\n",
    "    else:\n",
    "        column_transform_info = _fit_continuous(raw_data[[column_name]])\n",
    "\n",
    "    output_info_list.append(column_transform_info.output_info)\n",
    "    output_dimensions += column_transform_info.output_dimensions\n",
    "    column_transform_info_list.append(column_transform_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[SpanInfo(dim=1, activation_fn='tanh'),\n",
       "  SpanInfo(dim=3, activation_fn='softmax')],\n",
       " [SpanInfo(dim=1, activation_fn='tanh'),\n",
       "  SpanInfo(dim=5, activation_fn='softmax')],\n",
       " [SpanInfo(dim=1, activation_fn='tanh'),\n",
       "  SpanInfo(dim=5, activation_fn='softmax')],\n",
       " [SpanInfo(dim=14, activation_fn='softmax')],\n",
       " [SpanInfo(dim=39, activation_fn='softmax')],\n",
       " [SpanInfo(dim=21, activation_fn='softmax')]]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ColumnTransformInfo(column_name='injury_claim', column_type='continuous', transform=ClusterBasedNormalizer(model_missing_values=True), output_info=[SpanInfo(dim=1, activation_fn='tanh'), SpanInfo(dim=3, activation_fn='softmax')], output_dimensions=4),\n",
       " ColumnTransformInfo(column_name='property_claim', column_type='continuous', transform=ClusterBasedNormalizer(model_missing_values=True), output_info=[SpanInfo(dim=1, activation_fn='tanh'), SpanInfo(dim=5, activation_fn='softmax')], output_dimensions=6),\n",
       " ColumnTransformInfo(column_name='vehicle_claim', column_type='continuous', transform=ClusterBasedNormalizer(model_missing_values=True), output_info=[SpanInfo(dim=1, activation_fn='tanh'), SpanInfo(dim=5, activation_fn='softmax')], output_dimensions=6),\n",
       " ColumnTransformInfo(column_name='auto_make', column_type='discrete', transform=OneHotEncoder(), output_info=[SpanInfo(dim=14, activation_fn='softmax')], output_dimensions=14),\n",
       " ColumnTransformInfo(column_name='auto_model', column_type='discrete', transform=OneHotEncoder(), output_info=[SpanInfo(dim=39, activation_fn='softmax')], output_dimensions=39),\n",
       " ColumnTransformInfo(column_name='auto_year', column_type='discrete', transform=OneHotEncoder(), output_info=[SpanInfo(dim=21, activation_fn='softmax')], output_dimensions=21)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_transform_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim = output_dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 23:33:12.396374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "#define residual layer\n",
    "import tensorflow as tf\n",
    "import math\n",
    "class ResidualLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,input_dim, output_dim):\n",
    "        super(ResidualLayer, self).__init__()\n",
    "        bound = 1/math.sqrt(input_dim)\n",
    "        w_init = tf.keras.initializers.RandomUniform(minval=-bound, maxval=bound)\n",
    "        self.w = tf.Variable(\n",
    "            initial_value=w_init(shape=(input_dim, output_dim), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "        b_init = tf.keras.initializers.RandomUniform(minval=-bound, maxval=bound)\n",
    "        self.b = tf.Variable(\n",
    "            initial_value=b_init(shape=(output_dim,), dtype=\"float32\"), trainable=True\n",
    "        )\n",
    "    def call(self, inputs):\n",
    "        x = tf.matmul(inputs, self.w) + self.b\n",
    "        x = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum=0.9)(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        out = tf.concat([x, inputs],1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128 + 74\n",
    "generator_dim = [256, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 23:33:17.491700: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-06-07 23:33:17.493337: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-06-07 23:33:17.546275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.45GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-06-07 23:33:17.546486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:af:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.45GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-06-07 23:33:17.546511: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-06-07 23:33:17.548011: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-06-07 23:33:17.548075: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-06-07 23:33:17.549459: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-06-07 23:33:17.549701: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-06-07 23:33:17.551215: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-06-07 23:33:17.551998: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-06-07 23:33:17.555155: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-06-07 23:33:17.555826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2023-06-07 23:33:17.556354: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-07 23:33:17.557657: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-06-07 23:33:17.721008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.45GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-06-07 23:33:17.721202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:af:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.45GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-06-07 23:33:17.721239: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-06-07 23:33:17.721255: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-06-07 23:33:17.721264: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-06-07 23:33:17.721272: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-06-07 23:33:17.721280: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-06-07 23:33:17.721288: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-06-07 23:33:17.721297: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-06-07 23:33:17.721306: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-06-07 23:33:17.721811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2023-06-07 23:33:17.721839: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-06-07 23:33:18.408250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-06-07 23:33:18.408280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2023-06-07 23:33:18.408284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y \n",
      "2023-06-07 23:33:18.408286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N \n",
      "2023-06-07 23:33:18.409102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 45371 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:3b:00.0, compute capability: 7.5)\n",
      "2023-06-07 23:33:18.409771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 45379 MB memory) -> physical GPU (device: 1, name: Quadro RTX 8000, pci bus id: 0000:af:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:1'):\n",
    "    inp_gen = tf.keras.layers.Input(shape=(embedding_dim,))\n",
    "    input_dim = embedding_dim\n",
    "    x = inp_gen\n",
    "    for output_dim in generator_dim:\n",
    "       x = ResidualLayer(input_dim, output_dim)(x)\n",
    "       input_dim += output_dim\n",
    "    x = tf.keras.layers.Dense(units = data_dim)(x)\n",
    "    generator = tf.keras.models.Model(inp_gen, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 202)]             0         \n",
      "_________________________________________________________________\n",
      "residual_layer (ResidualLaye (None, 458)               51968     \n",
      "_________________________________________________________________\n",
      "residual_layer_1 (ResidualLa (None, 714)               117504    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 90)                64350     \n",
      "=================================================================\n",
      "Total params: 233,822\n",
      "Trainable params: 233,822\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply activation function to the output of generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gumble softmax function\n",
    "import tensorflow_probability as tfp\n",
    "def _gumbel_softmax(logits, tau=1.0, hard=False, dim=-1):\n",
    "        \"\"\"Samples from the Gumbel-Softmax distribution\n",
    "        :cite:`maddison2016concrete`, :cite:`jang2016categorical` and\n",
    "        optionally discretizes.\n",
    "        Parameters\n",
    "        ----------\n",
    "        logits: tf.Tensor\n",
    "            Un-normalized log probabilities.\n",
    "        tau: float, default=1.0\n",
    "            Non-negative scalar temperature.\n",
    "        hard: bool, default=False\n",
    "            If ``True``, the returned samples will be discretized as\n",
    "            one-hot vectors, but will be differentiated as soft samples.\n",
    "        dim: int, default=1\n",
    "            The dimension along which softmax will be computed.\n",
    "        Returns\n",
    "        -------\n",
    "        tf.Tensor\n",
    "            Sampled tensor of same shape as ``logits`` from the\n",
    "            Gumbel-Softmax distribution. If ``hard=True``, the returned samples\n",
    "            will be one-hot, otherwise they will be probability distributions\n",
    "            that sum to 1 across ``dim``.\n",
    "        \"\"\"\n",
    "\n",
    "        gumbel_dist = tfp.distributions.Gumbel(loc=0, scale=1)\n",
    "        gumbels = gumbel_dist.sample(tf.shape(logits))\n",
    "        gumbels = (logits + gumbels) / tau\n",
    "        output = tf.nn.softmax(gumbels, dim)\n",
    "\n",
    "        if hard:\n",
    "            index = tf.math.reduce_max(output, 1, keepdims=True)\n",
    "            output_hard = tf.cast(tf.equal(output, index), output.dtype)\n",
    "            output = tf.stop_gradient(output_hard - output) + output\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _apply_activate(data):\n",
    "        \"\"\"Apply proper activation function to the output of the generator.\"\"\"\n",
    "        data_t = []\n",
    "        st = 0\n",
    "        for column_info in transformer.output_info_list:\n",
    "            for span_info in column_info:\n",
    "                if span_info.activation_fn == 'tanh':\n",
    "                    ed = st + span_info.dim\n",
    "                    data_t.append(tf.math.tanh(data[:, st:ed]))\n",
    "                    st = ed\n",
    "                elif span_info.activation_fn == 'softmax':\n",
    "                    ed = st + span_info.dim\n",
    "                    transformed = _gumbel_softmax(data[:, st:ed], tau=0.2)\n",
    "                    data_t.append(transformed)\n",
    "                    st = ed\n",
    "                else:\n",
    "                    raise ValueError(f'Unexpected activation function {span_info.activation_fn}.')\n",
    "\n",
    "        return tf.concat(data_t, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "with tf.device('/gpu:1'):\n",
    "    BATCH_SIZE = 10\n",
    "    noise_dim = embedding_dim\n",
    "    noise = tf.random.normal((BATCH_SIZE, noise_dim))\n",
    "    noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 23:33:32.782988: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:1'):\n",
    "   data = generator(noise)\n",
    "   data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "data_t = []\n",
    "st = 0\n",
    "for column_info in output_info_list:\n",
    "    for span_info in column_info:\n",
    "        if span_info.activation_fn == 'tanh':\n",
    "            ed = st + span_info.dim\n",
    "            data_t.append(tf.math.tanh(data[:, st:ed]))\n",
    "            st = ed\n",
    "        elif span_info.activation_fn == 'softmax':\n",
    "            ed = st + span_info.dim\n",
    "            transformed = _gumbel_softmax(data[:, st:ed], tau=0.2)\n",
    "            data_t.append(transformed)\n",
    "            st = ed\n",
    "        else:\n",
    "            raise ValueError(f'Unexpected activation function {span_info.activation_fn}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       " array([[-0.46928915],\n",
       "        [ 0.95056313],\n",
       "        [-0.82112604],\n",
       "        [ 0.7702087 ],\n",
       "        [ 0.9398631 ],\n",
       "        [ 0.40016192],\n",
       "        [ 0.567068  ],\n",
       "        [ 0.6374217 ],\n",
       "        [ 0.14365566],\n",
       "        [ 0.7339894 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10, 3), dtype=float32, numpy=\n",
       " array([[5.9801809e-05, 9.9994016e-01, 1.9737163e-10],\n",
       "        [1.0000000e+00, 2.8790041e-17, 1.2520658e-18],\n",
       "        [1.9458004e-05, 5.3363975e-02, 9.4661653e-01],\n",
       "        [7.2719109e-01, 2.6197481e-01, 1.0834107e-02],\n",
       "        [3.3437785e-02, 2.8935727e-01, 6.7720497e-01],\n",
       "        [6.5587270e-01, 1.5700830e-04, 3.4397033e-01],\n",
       "        [4.6598888e-12, 1.5961944e-12, 1.0000000e+00],\n",
       "        [3.6696589e-01, 3.4121264e-02, 5.9891284e-01],\n",
       "        [4.1588614e-06, 9.9957281e-01, 4.2295986e-04],\n",
       "        [4.9342336e-08, 1.5303436e-01, 8.4696561e-01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       " array([[ 0.06272586],\n",
       "        [ 0.7257585 ],\n",
       "        [ 0.1789877 ],\n",
       "        [ 0.0686576 ],\n",
       "        [-0.78039825],\n",
       "        [-0.74511546],\n",
       "        [ 0.06853048],\n",
       "        [ 0.00667067],\n",
       "        [-0.6901845 ],\n",
       "        [ 0.83304834]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10, 5), dtype=float32, numpy=\n",
       " array([[5.6897014e-05, 1.0332711e-03, 5.3124166e-01, 4.6766815e-01,\n",
       "         6.9509163e-08],\n",
       "        [4.7770343e-05, 1.4993373e-02, 3.4103035e-08, 9.8416859e-01,\n",
       "         7.9025951e-04],\n",
       "        [1.7986095e-02, 4.5086986e-06, 2.0419291e-01, 1.7968794e-04,\n",
       "         7.7763683e-01],\n",
       "        [1.0395113e-05, 9.9747097e-01, 1.6934496e-09, 1.2220287e-08,\n",
       "         2.5186746e-03],\n",
       "        [2.1403808e-09, 2.0969394e-05, 5.5581664e-09, 9.9997902e-01,\n",
       "         6.5992651e-09],\n",
       "        [6.3057315e-10, 8.8681554e-05, 2.2291209e-09, 5.5806066e-09,\n",
       "         9.9991131e-01],\n",
       "        [1.5759040e-03, 1.4459199e-01, 3.0662316e-06, 7.9607475e-01,\n",
       "         5.7754338e-02],\n",
       "        [7.8044501e-08, 9.5738137e-09, 8.2604057e-01, 1.2389023e-04,\n",
       "         1.7383547e-01],\n",
       "        [1.1538978e-07, 1.5968885e-01, 3.7297461e-02, 5.8779660e-05,\n",
       "         8.0295485e-01],\n",
       "        [2.0877913e-01, 1.0595376e-01, 6.5632308e-01, 2.8943682e-02,\n",
       "         2.8526026e-07]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       " array([[-0.42510387],\n",
       "        [ 0.39670172],\n",
       "        [-0.5206634 ],\n",
       "        [-0.8514238 ],\n",
       "        [-0.92777056],\n",
       "        [-0.6415471 ],\n",
       "        [-0.7835872 ],\n",
       "        [ 0.1854971 ],\n",
       "        [-0.7433531 ],\n",
       "        [-0.00768012]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10, 5), dtype=float32, numpy=\n",
       " array([[9.92195845e-01, 2.47599257e-08, 3.10022733e-05, 5.88513649e-06,\n",
       "         7.76728429e-03],\n",
       "        [3.47946440e-07, 5.36643405e-08, 4.65977790e-09, 9.99999523e-01,\n",
       "         1.74100279e-07],\n",
       "        [1.27562488e-10, 7.25373742e-04, 9.99274194e-01, 1.40304091e-09,\n",
       "         5.02808291e-07],\n",
       "        [9.99987245e-01, 2.26891871e-07, 6.95962717e-06, 5.45366856e-06,\n",
       "         1.11433536e-07],\n",
       "        [3.81984195e-04, 7.28115197e-07, 3.90794003e-06, 9.99613106e-01,\n",
       "         2.12567997e-07],\n",
       "        [5.54457620e-05, 1.53637901e-01, 8.46276283e-01, 1.31958416e-06,\n",
       "         2.90726348e-05],\n",
       "        [8.76496255e-01, 4.99197207e-02, 4.38653380e-02, 1.56647190e-02,\n",
       "         1.40540618e-02],\n",
       "        [1.07898835e-07, 9.99954820e-01, 1.08526441e-08, 4.50852858e-05,\n",
       "         1.63822525e-10],\n",
       "        [9.99992013e-01, 5.03212914e-06, 6.21993024e-07, 1.28110628e-06,\n",
       "         1.02954994e-06],\n",
       "        [4.64304954e-01, 4.76753533e-01, 4.26471531e-02, 2.44061113e-03,\n",
       "         1.38537046e-02]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10, 14), dtype=float32, numpy=\n",
       " array([[3.16408150e-05, 6.52995823e-07, 2.76290348e-06, 1.03650741e-07,\n",
       "         2.96262659e-09, 4.22370831e-05, 2.09763311e-04, 1.25429665e-06,\n",
       "         9.99704659e-01, 4.50257756e-12, 4.44563775e-10, 2.33435645e-12,\n",
       "         2.36961633e-08, 6.91570585e-06],\n",
       "        [8.28903935e-14, 5.45911618e-08, 1.35289635e-09, 3.15539261e-12,\n",
       "         6.88826501e-01, 5.43614242e-12, 7.15100654e-08, 1.98817918e-13,\n",
       "         7.87565035e-09, 7.34472749e-08, 6.22073018e-11, 3.11173230e-01,\n",
       "         6.63143140e-09, 7.59326380e-09],\n",
       "        [2.50891870e-04, 2.64855021e-06, 2.34469351e-08, 3.45054013e-03,\n",
       "         3.19433480e-10, 1.70632422e-01, 2.57752079e-04, 6.02476299e-01,\n",
       "         1.19681950e-04, 2.13167116e-01, 3.12060615e-06, 1.48050918e-03,\n",
       "         1.84453114e-07, 8.15880671e-03],\n",
       "        [3.88205353e-06, 6.26993080e-09, 3.35667664e-07, 1.53382192e-03,\n",
       "         5.51658809e-01, 2.35171552e-04, 3.83498955e-10, 3.43404660e-09,\n",
       "         2.18489987e-07, 4.46567625e-01, 5.26665822e-08, 1.57555857e-10,\n",
       "         5.26639177e-10, 9.51901669e-09],\n",
       "        [3.77585420e-12, 5.05024800e-04, 2.29913428e-01, 3.67289643e-10,\n",
       "         1.35568998e-05, 7.90929366e-09, 2.55025924e-07, 6.42424891e-10,\n",
       "         1.45922215e-07, 7.69504607e-01, 2.42297974e-05, 3.85263193e-05,\n",
       "         1.42539079e-07, 5.46705472e-08],\n",
       "        [4.52930748e-01, 4.95130807e-01, 5.29396115e-03, 1.41868150e-05,\n",
       "         2.63906287e-07, 5.66687334e-07, 4.53879423e-02, 3.33159915e-05,\n",
       "         1.87424637e-04, 2.23046285e-07, 1.01094798e-03, 7.96888162e-06,\n",
       "         1.60035449e-06, 8.34917344e-08],\n",
       "        [5.86507394e-06, 4.79120799e-10, 3.49421636e-13, 1.59487035e-03,\n",
       "         5.36097048e-07, 4.10338034e-05, 1.78972392e-08, 1.81536052e-07,\n",
       "         9.98193443e-01, 1.33083086e-10, 3.16622284e-09, 4.58415386e-08,\n",
       "         8.53243591e-08, 1.63947974e-04],\n",
       "        [1.27495483e-07, 6.57915552e-06, 1.55548816e-12, 5.19577104e-10,\n",
       "         1.06414405e-10, 1.44615651e-05, 9.96002734e-01, 6.30283159e-09,\n",
       "         3.28212593e-07, 3.58232714e-11, 1.54495239e-09, 3.77076794e-03,\n",
       "         1.89281898e-04, 1.57745526e-05],\n",
       "        [1.39923706e-11, 7.78631879e-13, 1.90894015e-15, 8.46472532e-18,\n",
       "         3.48675620e-17, 8.77968716e-07, 7.26428334e-05, 9.99926567e-01,\n",
       "         3.23521287e-14, 8.56301141e-12, 3.30092399e-13, 5.10654088e-16,\n",
       "         1.54224117e-14, 2.57399813e-11],\n",
       "        [4.06802911e-08, 9.99920607e-01, 2.09529321e-11, 4.62555411e-11,\n",
       "         1.23776019e-07, 2.65611903e-12, 1.36376244e-09, 1.94841755e-06,\n",
       "         9.94221864e-07, 1.22118289e-08, 9.56946522e-09, 6.30426730e-05,\n",
       "         6.96580310e-06, 6.33086938e-06]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10, 39), dtype=float32, numpy=\n",
       " array([[4.94935454e-15, 8.56819726e-10, 2.26630398e-11, 2.76565935e-08,\n",
       "         1.32608841e-10, 7.04967226e-14, 4.82928855e-13, 4.34302844e-10,\n",
       "         1.01794996e-07, 1.75669996e-15, 2.87612078e-12, 3.01356440e-11,\n",
       "         9.64627933e-10, 7.87640135e-13, 3.83290811e-13, 2.32915208e-02,\n",
       "         2.64640458e-12, 1.54112851e-11, 2.25674839e-12, 3.64446407e-12,\n",
       "         2.46220774e-12, 2.36580709e-05, 9.00452335e-09, 2.12980883e-10,\n",
       "         6.46328902e-09, 1.85896223e-08, 4.08656670e-05, 1.03148545e-09,\n",
       "         5.35810152e-09, 9.76643741e-01, 1.23176675e-14, 6.07490566e-13,\n",
       "         4.14668699e-09, 4.63399527e-11, 8.12417078e-11, 2.51827743e-11,\n",
       "         1.06556229e-10, 5.63849127e-08, 1.47662806e-12],\n",
       "        [5.75856376e-12, 1.13516435e-04, 8.99740840e-13, 8.39609947e-06,\n",
       "         1.00803126e-08, 1.51478461e-12, 1.18137444e-09, 1.32567748e-05,\n",
       "         1.13025289e-09, 1.09904225e-10, 5.89494277e-07, 2.02628483e-10,\n",
       "         3.92302695e-07, 9.67384050e-13, 2.17256904e-13, 9.77659953e-10,\n",
       "         2.00442929e-09, 3.70113207e-09, 8.65293785e-13, 4.63705888e-04,\n",
       "         8.64875532e-11, 5.70652725e-09, 4.16886905e-07, 4.97037007e-08,\n",
       "         6.85751109e-11, 1.14366943e-02, 1.11559420e-04, 3.85859530e-12,\n",
       "         8.46773128e-06, 2.91047698e-12, 6.43257737e-01, 2.62435805e-07,\n",
       "         1.00679709e-09, 8.60937899e-09, 5.89328298e-15, 7.19089393e-13,\n",
       "         1.69144365e-09, 3.44585001e-01, 5.54090995e-10],\n",
       "        [1.75436419e-11, 1.24400598e-12, 2.22673232e-04, 3.95896094e-11,\n",
       "         9.93541499e-11, 5.65630853e-01, 8.67009298e-10, 7.74772579e-10,\n",
       "         6.44782449e-06, 3.12959547e-09, 1.16508678e-10, 5.08818717e-04,\n",
       "         2.63617683e-10, 1.92977132e-05, 3.51129570e-10, 1.48307864e-08,\n",
       "         1.24494682e-05, 9.20093537e-13, 3.74920581e-11, 3.04010715e-02,\n",
       "         4.55571397e-04, 1.49271966e-11, 8.79297991e-14, 1.68036376e-10,\n",
       "         1.41050114e-05, 4.20634594e-09, 3.03731947e-13, 4.29210161e-08,\n",
       "         9.18876530e-09, 1.99478469e-03, 4.00729895e-01, 1.10670877e-14,\n",
       "         3.16179705e-09, 2.47537147e-11, 2.11789234e-06, 1.81187318e-06,\n",
       "         1.47930765e-11, 7.11534609e-09, 4.21501989e-09],\n",
       "        [5.57069191e-12, 1.46199123e-14, 5.37386818e-17, 1.23406083e-18,\n",
       "         3.25454906e-11, 5.48734330e-18, 1.37044397e-17, 1.66666019e-12,\n",
       "         1.10852467e-17, 2.29410880e-16, 2.44072307e-14, 3.60627110e-12,\n",
       "         1.05256111e-17, 1.87506716e-12, 2.49563662e-21, 8.25912183e-19,\n",
       "         7.57741447e-17, 1.23067257e-16, 6.14394607e-16, 1.98950813e-18,\n",
       "         9.63928170e-14, 4.14021598e-18, 4.77023976e-12, 1.56831145e-17,\n",
       "         1.19854209e-16, 2.21117726e-16, 5.40085961e-14, 1.03947658e-11,\n",
       "         1.00496955e-07, 3.86741549e-19, 6.97538137e-14, 9.99999881e-01,\n",
       "         1.34787375e-19, 2.30875911e-18, 5.09255173e-11, 2.98114516e-16,\n",
       "         2.35276791e-19, 2.87051521e-10, 3.82197095e-16],\n",
       "        [3.02907961e-06, 1.84937807e-12, 1.90136462e-10, 1.87940791e-03,\n",
       "         3.54433361e-13, 4.56110809e-11, 1.02351648e-10, 2.75616650e-03,\n",
       "         1.31183793e-03, 6.71402595e-05, 1.93894721e-06, 3.73792641e-09,\n",
       "         4.07816107e-11, 7.70039144e-09, 5.47179001e-13, 4.08829770e-09,\n",
       "         1.72116499e-16, 3.87072241e-09, 1.69765080e-05, 9.41134254e-11,\n",
       "         4.37954848e-13, 1.43924803e-12, 1.34119871e-09, 3.22811356e-05,\n",
       "         5.21196810e-08, 8.68501882e-10, 1.05586505e-05, 9.93735731e-01,\n",
       "         2.98584268e-08, 1.84336168e-04, 1.57386153e-11, 1.69149395e-12,\n",
       "         3.51617871e-07, 2.11984670e-07, 2.53669447e-10, 3.42078025e-15,\n",
       "         1.05838774e-14, 1.05118236e-12, 5.39105869e-13],\n",
       "        [1.72701627e-11, 2.29205011e-09, 2.36482847e-05, 2.95603750e-11,\n",
       "         1.11161725e-07, 3.37228130e-07, 1.00117258e-11, 2.31388049e-06,\n",
       "         6.06959927e-10, 1.26955806e-08, 6.44274110e-07, 1.30403263e-04,\n",
       "         2.48595256e-07, 1.93385201e-08, 3.31322678e-11, 5.95914753e-05,\n",
       "         1.26222009e-03, 3.72868181e-10, 1.90472892e-05, 8.01796432e-06,\n",
       "         1.99242489e-08, 7.28574669e-05, 1.71057069e-09, 4.46163284e-07,\n",
       "         3.84721552e-08, 9.02786255e-01, 2.63780784e-08, 7.43103179e-09,\n",
       "         2.21586326e-14, 1.75073154e-07, 1.84803775e-05, 1.14201171e-09,\n",
       "         9.55293924e-02, 4.00454212e-07, 1.44196911e-11, 8.40048378e-05,\n",
       "         6.40892843e-14, 1.40460406e-06, 6.55530144e-12],\n",
       "        [5.24553867e-09, 1.17492531e-08, 3.29869199e-09, 5.09022655e-08,\n",
       "         6.11971151e-12, 2.77694256e-11, 1.63660674e-09, 8.39873672e-01,\n",
       "         1.12110947e-03, 4.55372762e-09, 1.04057649e-03, 9.93123322e-05,\n",
       "         7.60406405e-10, 8.25738523e-12, 5.94416742e-05, 2.52831983e-03,\n",
       "         1.35952786e-01, 8.48850003e-04, 7.09406631e-11, 7.08253386e-11,\n",
       "         9.38992661e-10, 5.88037175e-10, 2.01711439e-10, 1.58346742e-02,\n",
       "         4.31716330e-07, 2.06378150e-08, 2.54092552e-03, 4.07641710e-06,\n",
       "         2.65171147e-05, 3.42986795e-07, 2.63912087e-10, 4.60372213e-10,\n",
       "         6.45137916e-05, 3.59202890e-10, 2.58352333e-14, 1.07904285e-07,\n",
       "         1.22540575e-10, 5.31286848e-10, 4.33504647e-06],\n",
       "        [1.76639166e-08, 1.23362868e-13, 6.72129374e-08, 1.10285652e-12,\n",
       "         7.81335385e-10, 3.28482331e-13, 2.64627357e-14, 5.97218412e-12,\n",
       "         1.98493175e-12, 1.18151463e-12, 6.09190259e-12, 3.84136555e-17,\n",
       "         3.35667149e-13, 7.18313145e-14, 9.99999881e-01, 1.33812586e-17,\n",
       "         1.79972106e-14, 1.68451433e-10, 7.68591873e-16, 6.71980841e-15,\n",
       "         1.73559819e-10, 6.50740638e-13, 3.02317026e-11, 6.31057863e-16,\n",
       "         5.60988318e-21, 8.46912263e-11, 4.88535062e-18, 1.18274164e-15,\n",
       "         4.06050959e-14, 1.79417659e-09, 8.73059351e-12, 6.30691449e-14,\n",
       "         1.83824215e-16, 3.38916950e-11, 3.36906847e-14, 4.93839763e-17,\n",
       "         4.85483181e-16, 3.02963557e-11, 5.10782931e-13],\n",
       "        [3.59284915e-14, 8.27587651e-12, 3.57323492e-14, 1.18538939e-08,\n",
       "         5.26045943e-11, 1.19742389e-12, 2.49611026e-10, 5.36761018e-11,\n",
       "         4.47412662e-11, 9.07741271e-10, 8.00835906e-14, 1.77848449e-06,\n",
       "         2.45246801e-09, 4.69423611e-09, 2.38848361e-06, 1.78941875e-08,\n",
       "         1.58849198e-05, 6.01277437e-13, 9.90335703e-01, 1.04445302e-13,\n",
       "         3.69747366e-09, 7.64275665e-09, 1.01483426e-08, 1.75456216e-06,\n",
       "         5.33344835e-09, 6.17378162e-11, 6.92089897e-09, 2.47046217e-10,\n",
       "         8.77497239e-13, 9.59634688e-03, 3.35712393e-05, 1.08588284e-10,\n",
       "         7.23268559e-14, 2.97431075e-06, 2.96762208e-13, 4.67609512e-13,\n",
       "         4.72867578e-11, 4.91122324e-15, 9.48755314e-06],\n",
       "        [1.04609410e-06, 7.79862876e-06, 2.40843612e-09, 1.13106822e-08,\n",
       "         8.38848546e-10, 4.37279439e-08, 7.49975637e-09, 9.71244276e-07,\n",
       "         1.98943328e-09, 2.31022618e-10, 1.35717210e-06, 1.16181863e-10,\n",
       "         3.91234993e-04, 2.70098202e-12, 5.27449991e-14, 1.06694529e-08,\n",
       "         1.39793087e-07, 3.90919240e-07, 1.74489578e-09, 3.03799084e-07,\n",
       "         3.13862103e-07, 3.62073371e-10, 9.38235978e-09, 9.64424166e-11,\n",
       "         5.41455756e-06, 9.31884733e-06, 9.99275148e-01, 2.30088466e-11,\n",
       "         8.41558434e-10, 4.27209712e-10, 4.78661466e-09, 1.70974115e-08,\n",
       "         1.22729489e-08, 1.87841404e-04, 2.20565504e-08, 9.79605108e-09,\n",
       "         1.15264884e-04, 3.26316558e-06, 1.95149192e-11]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10, 21), dtype=float32, numpy=\n",
       " array([[7.41125120e-07, 1.58942157e-07, 3.61095724e-12, 2.01773103e-02,\n",
       "         5.34641753e-09, 1.44447752e-08, 2.36583073e-08, 9.25612866e-08,\n",
       "         1.62845045e-05, 7.87341303e-11, 9.79801655e-01, 5.23798187e-16,\n",
       "         3.66739573e-06, 3.09448474e-11, 1.90772506e-12, 1.47370356e-08,\n",
       "         3.34907391e-09, 1.97549835e-14, 5.56727864e-09, 8.43887044e-11,\n",
       "         2.46147742e-12],\n",
       "        [3.24731758e-07, 6.61051745e-05, 8.14547150e-07, 2.39157548e-11,\n",
       "         2.62523944e-11, 2.44161856e-06, 4.55699888e-12, 7.96235966e-09,\n",
       "         5.70337000e-10, 6.50280970e-04, 4.66583933e-12, 1.02257509e-07,\n",
       "         1.71400665e-04, 3.38142924e-03, 7.43599005e-09, 1.33433931e-09,\n",
       "         1.14187074e-07, 4.95186336e-02, 3.73754701e-05, 9.46170986e-01,\n",
       "         3.04084008e-10],\n",
       "        [9.44162391e-13, 2.82879482e-05, 3.29679608e-08, 1.72724367e-06,\n",
       "         1.63536957e-12, 9.99954462e-01, 1.19497223e-09, 4.52738789e-08,\n",
       "         9.65662184e-06, 2.87366106e-06, 7.03865959e-12, 6.88137391e-07,\n",
       "         4.66723726e-08, 1.36750211e-09, 2.90302538e-09, 8.98901509e-11,\n",
       "         2.05688048e-06, 3.91309962e-09, 2.26781580e-08, 1.97878536e-09,\n",
       "         2.21806260e-07],\n",
       "        [3.16167736e-09, 8.82665063e-06, 3.19363949e-07, 4.09208296e-04,\n",
       "         1.22444328e-06, 6.04466186e-04, 7.88028615e-07, 4.69346414e-05,\n",
       "         2.72126310e-02, 8.36256266e-01, 3.14929028e-04, 1.88789971e-04,\n",
       "         5.20357344e-06, 2.25040203e-04, 7.23241246e-05, 1.11561876e-05,\n",
       "         2.53692153e-04, 7.93978838e-09, 1.34388104e-01, 3.60035757e-09,\n",
       "         3.96490769e-08],\n",
       "        [1.34146021e-07, 1.04320515e-03, 5.07592013e-08, 8.92640829e-01,\n",
       "         1.04951025e-04, 3.28646471e-10, 5.25806759e-11, 7.30073779e-09,\n",
       "         1.19685812e-03, 6.66946789e-06, 1.04998142e-01, 1.74464798e-08,\n",
       "         1.62170807e-07, 1.76916523e-10, 7.77705554e-06, 8.08899131e-07,\n",
       "         2.61580047e-09, 8.55570370e-09, 4.92545604e-09, 4.46868000e-08,\n",
       "         3.50955332e-07],\n",
       "        [2.95602018e-03, 5.26444346e-04, 1.79059803e-01, 5.04030474e-03,\n",
       "         3.72802361e-07, 3.00228919e-07, 2.14739814e-02, 2.65613585e-06,\n",
       "         6.41412316e-06, 3.98199882e-05, 1.90023445e-06, 9.82481288e-04,\n",
       "         6.07398987e-01, 2.98911496e-03, 1.27150226e-04, 3.24797438e-04,\n",
       "         1.73221976e-01, 1.95046523e-04, 5.48686785e-07, 5.63949021e-03,\n",
       "         1.22643605e-05],\n",
       "        [7.12396344e-04, 3.74185248e-07, 3.94720843e-07, 2.20225756e-05,\n",
       "         6.13438811e-09, 2.58319408e-13, 2.24706741e-06, 3.77372383e-10,\n",
       "         5.25297805e-09, 4.43953052e-02, 4.72430450e-08, 8.56300062e-08,\n",
       "         5.24772611e-03, 1.05004574e-07, 8.83650861e-11, 1.51111381e-04,\n",
       "         5.21949939e-02, 4.66203812e-12, 1.14853248e-01, 7.82419980e-01,\n",
       "         1.42591369e-10],\n",
       "        [3.41597006e-05, 6.80351839e-14, 3.91218666e-04, 8.49466371e-14,\n",
       "         1.46458788e-07, 6.72514201e-04, 8.33744358e-12, 8.42870695e-13,\n",
       "         6.19926110e-10, 1.09157138e-01, 1.52358055e-08, 2.44630116e-09,\n",
       "         8.89585495e-01, 5.34242789e-13, 3.66860178e-07, 2.03586814e-09,\n",
       "         1.97926209e-09, 1.05766498e-11, 1.58648967e-04, 1.14145776e-11,\n",
       "         4.16706087e-07],\n",
       "        [2.26544312e-08, 5.30949798e-11, 5.87642565e-12, 9.99686003e-01,\n",
       "         2.70866889e-14, 9.73541447e-16, 2.99499364e-14, 2.00624066e-12,\n",
       "         2.48890981e-04, 2.20707619e-11, 1.83165969e-13, 1.04242135e-08,\n",
       "         5.22473002e-11, 6.11801879e-05, 5.07803261e-12, 8.32145186e-10,\n",
       "         3.92433321e-06, 5.29966280e-15, 6.77477701e-08, 1.15433782e-11,\n",
       "         2.34988092e-12],\n",
       "        [5.34012976e-08, 9.53064682e-06, 3.10122065e-04, 3.78860103e-04,\n",
       "         7.47294937e-09, 1.00518455e-05, 2.91028246e-03, 8.15782100e-02,\n",
       "         1.03717124e-04, 7.77816924e-04, 6.79945344e-08, 1.76255867e-06,\n",
       "         6.86600688e-05, 1.43021496e-03, 8.11757818e-02, 7.73928285e-01,\n",
       "         6.32855006e-07, 1.11125148e-04, 2.43052909e-06, 1.28319738e-02,\n",
       "         4.43704389e-02]], dtype=float32)>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 90), dtype=float32, numpy=\n",
       "array([[-4.69289154e-01,  5.98018087e-05,  9.99940157e-01,\n",
       "         1.97371633e-10,  6.27258644e-02,  5.68970136e-05,\n",
       "         1.03327108e-03,  5.31241655e-01,  4.67668146e-01,\n",
       "         6.95091629e-08, -4.25103873e-01,  9.92195845e-01,\n",
       "         2.47599257e-08,  3.10022733e-05,  5.88513649e-06,\n",
       "         7.76728429e-03,  3.16408150e-05,  6.52995823e-07,\n",
       "         2.76290348e-06,  1.03650741e-07,  2.96262659e-09,\n",
       "         4.22370831e-05,  2.09763311e-04,  1.25429665e-06,\n",
       "         9.99704659e-01,  4.50257756e-12,  4.44563775e-10,\n",
       "         2.33435645e-12,  2.36961633e-08,  6.91570585e-06,\n",
       "         4.94935454e-15,  8.56819726e-10,  2.26630398e-11,\n",
       "         2.76565935e-08,  1.32608841e-10,  7.04967226e-14,\n",
       "         4.82928855e-13,  4.34302844e-10,  1.01794996e-07,\n",
       "         1.75669996e-15,  2.87612078e-12,  3.01356440e-11,\n",
       "         9.64627933e-10,  7.87640135e-13,  3.83290811e-13,\n",
       "         2.32915208e-02,  2.64640458e-12,  1.54112851e-11,\n",
       "         2.25674839e-12,  3.64446407e-12,  2.46220774e-12,\n",
       "         2.36580709e-05,  9.00452335e-09,  2.12980883e-10,\n",
       "         6.46328902e-09,  1.85896223e-08,  4.08656670e-05,\n",
       "         1.03148545e-09,  5.35810152e-09,  9.76643741e-01,\n",
       "         1.23176675e-14,  6.07490566e-13,  4.14668699e-09,\n",
       "         4.63399527e-11,  8.12417078e-11,  2.51827743e-11,\n",
       "         1.06556229e-10,  5.63849127e-08,  1.47662806e-12,\n",
       "         7.41125120e-07,  1.58942157e-07,  3.61095724e-12,\n",
       "         2.01773103e-02,  5.34641753e-09,  1.44447752e-08,\n",
       "         2.36583073e-08,  9.25612866e-08,  1.62845045e-05,\n",
       "         7.87341303e-11,  9.79801655e-01,  5.23798187e-16,\n",
       "         3.66739573e-06,  3.09448474e-11,  1.90772506e-12,\n",
       "         1.47370356e-08,  3.34907391e-09,  1.97549835e-14,\n",
       "         5.56727864e-09,  8.43887044e-11,  2.46147742e-12],\n",
       "       [ 9.50563133e-01,  1.00000000e+00,  2.87900411e-17,\n",
       "         1.25206576e-18,  7.25758493e-01,  4.77703434e-05,\n",
       "         1.49933733e-02,  3.41030351e-08,  9.84168589e-01,\n",
       "         7.90259510e-04,  3.96701723e-01,  3.47946440e-07,\n",
       "         5.36643405e-08,  4.65977790e-09,  9.99999523e-01,\n",
       "         1.74100279e-07,  8.28903935e-14,  5.45911618e-08,\n",
       "         1.35289635e-09,  3.15539261e-12,  6.88826501e-01,\n",
       "         5.43614242e-12,  7.15100654e-08,  1.98817918e-13,\n",
       "         7.87565035e-09,  7.34472749e-08,  6.22073018e-11,\n",
       "         3.11173230e-01,  6.63143140e-09,  7.59326380e-09,\n",
       "         5.75856376e-12,  1.13516435e-04,  8.99740840e-13,\n",
       "         8.39609947e-06,  1.00803126e-08,  1.51478461e-12,\n",
       "         1.18137444e-09,  1.32567748e-05,  1.13025289e-09,\n",
       "         1.09904225e-10,  5.89494277e-07,  2.02628483e-10,\n",
       "         3.92302695e-07,  9.67384050e-13,  2.17256904e-13,\n",
       "         9.77659953e-10,  2.00442929e-09,  3.70113207e-09,\n",
       "         8.65293785e-13,  4.63705888e-04,  8.64875532e-11,\n",
       "         5.70652725e-09,  4.16886905e-07,  4.97037007e-08,\n",
       "         6.85751109e-11,  1.14366943e-02,  1.11559420e-04,\n",
       "         3.85859530e-12,  8.46773128e-06,  2.91047698e-12,\n",
       "         6.43257737e-01,  2.62435805e-07,  1.00679709e-09,\n",
       "         8.60937899e-09,  5.89328298e-15,  7.19089393e-13,\n",
       "         1.69144365e-09,  3.44585001e-01,  5.54090995e-10,\n",
       "         3.24731758e-07,  6.61051745e-05,  8.14547150e-07,\n",
       "         2.39157548e-11,  2.62523944e-11,  2.44161856e-06,\n",
       "         4.55699888e-12,  7.96235966e-09,  5.70337000e-10,\n",
       "         6.50280970e-04,  4.66583933e-12,  1.02257509e-07,\n",
       "         1.71400665e-04,  3.38142924e-03,  7.43599005e-09,\n",
       "         1.33433931e-09,  1.14187074e-07,  4.95186336e-02,\n",
       "         3.73754701e-05,  9.46170986e-01,  3.04084008e-10],\n",
       "       [-8.21126044e-01,  1.94580043e-05,  5.33639751e-02,\n",
       "         9.46616530e-01,  1.78987697e-01,  1.79860946e-02,\n",
       "         4.50869857e-06,  2.04192907e-01,  1.79687937e-04,\n",
       "         7.77636826e-01, -5.20663381e-01,  1.27562488e-10,\n",
       "         7.25373742e-04,  9.99274194e-01,  1.40304091e-09,\n",
       "         5.02808291e-07,  2.50891870e-04,  2.64855021e-06,\n",
       "         2.34469351e-08,  3.45054013e-03,  3.19433480e-10,\n",
       "         1.70632422e-01,  2.57752079e-04,  6.02476299e-01,\n",
       "         1.19681950e-04,  2.13167116e-01,  3.12060615e-06,\n",
       "         1.48050918e-03,  1.84453114e-07,  8.15880671e-03,\n",
       "         1.75436419e-11,  1.24400598e-12,  2.22673232e-04,\n",
       "         3.95896094e-11,  9.93541499e-11,  5.65630853e-01,\n",
       "         8.67009298e-10,  7.74772579e-10,  6.44782449e-06,\n",
       "         3.12959547e-09,  1.16508678e-10,  5.08818717e-04,\n",
       "         2.63617683e-10,  1.92977132e-05,  3.51129570e-10,\n",
       "         1.48307864e-08,  1.24494682e-05,  9.20093537e-13,\n",
       "         3.74920581e-11,  3.04010715e-02,  4.55571397e-04,\n",
       "         1.49271966e-11,  8.79297991e-14,  1.68036376e-10,\n",
       "         1.41050114e-05,  4.20634594e-09,  3.03731947e-13,\n",
       "         4.29210161e-08,  9.18876530e-09,  1.99478469e-03,\n",
       "         4.00729895e-01,  1.10670877e-14,  3.16179705e-09,\n",
       "         2.47537147e-11,  2.11789234e-06,  1.81187318e-06,\n",
       "         1.47930765e-11,  7.11534609e-09,  4.21501989e-09,\n",
       "         9.44162391e-13,  2.82879482e-05,  3.29679608e-08,\n",
       "         1.72724367e-06,  1.63536957e-12,  9.99954462e-01,\n",
       "         1.19497223e-09,  4.52738789e-08,  9.65662184e-06,\n",
       "         2.87366106e-06,  7.03865959e-12,  6.88137391e-07,\n",
       "         4.66723726e-08,  1.36750211e-09,  2.90302538e-09,\n",
       "         8.98901509e-11,  2.05688048e-06,  3.91309962e-09,\n",
       "         2.26781580e-08,  1.97878536e-09,  2.21806260e-07],\n",
       "       [ 7.70208716e-01,  7.27191091e-01,  2.61974812e-01,\n",
       "         1.08341072e-02,  6.86575994e-02,  1.03951133e-05,\n",
       "         9.97470975e-01,  1.69344960e-09,  1.22202870e-08,\n",
       "         2.51867459e-03, -8.51423800e-01,  9.99987245e-01,\n",
       "         2.26891871e-07,  6.95962717e-06,  5.45366856e-06,\n",
       "         1.11433536e-07,  3.88205353e-06,  6.26993080e-09,\n",
       "         3.35667664e-07,  1.53382192e-03,  5.51658809e-01,\n",
       "         2.35171552e-04,  3.83498955e-10,  3.43404660e-09,\n",
       "         2.18489987e-07,  4.46567625e-01,  5.26665822e-08,\n",
       "         1.57555857e-10,  5.26639177e-10,  9.51901669e-09,\n",
       "         5.57069191e-12,  1.46199123e-14,  5.37386818e-17,\n",
       "         1.23406083e-18,  3.25454906e-11,  5.48734330e-18,\n",
       "         1.37044397e-17,  1.66666019e-12,  1.10852467e-17,\n",
       "         2.29410880e-16,  2.44072307e-14,  3.60627110e-12,\n",
       "         1.05256111e-17,  1.87506716e-12,  2.49563662e-21,\n",
       "         8.25912183e-19,  7.57741447e-17,  1.23067257e-16,\n",
       "         6.14394607e-16,  1.98950813e-18,  9.63928170e-14,\n",
       "         4.14021598e-18,  4.77023976e-12,  1.56831145e-17,\n",
       "         1.19854209e-16,  2.21117726e-16,  5.40085961e-14,\n",
       "         1.03947658e-11,  1.00496955e-07,  3.86741549e-19,\n",
       "         6.97538137e-14,  9.99999881e-01,  1.34787375e-19,\n",
       "         2.30875911e-18,  5.09255173e-11,  2.98114516e-16,\n",
       "         2.35276791e-19,  2.87051521e-10,  3.82197095e-16,\n",
       "         3.16167736e-09,  8.82665063e-06,  3.19363949e-07,\n",
       "         4.09208296e-04,  1.22444328e-06,  6.04466186e-04,\n",
       "         7.88028615e-07,  4.69346414e-05,  2.72126310e-02,\n",
       "         8.36256266e-01,  3.14929028e-04,  1.88789971e-04,\n",
       "         5.20357344e-06,  2.25040203e-04,  7.23241246e-05,\n",
       "         1.11561876e-05,  2.53692153e-04,  7.93978838e-09,\n",
       "         1.34388104e-01,  3.60035757e-09,  3.96490769e-08],\n",
       "       [ 9.39863086e-01,  3.34377848e-02,  2.89357275e-01,\n",
       "         6.77204967e-01, -7.80398250e-01,  2.14038076e-09,\n",
       "         2.09693935e-05,  5.55816637e-09,  9.99979019e-01,\n",
       "         6.59926513e-09, -9.27770555e-01,  3.81984195e-04,\n",
       "         7.28115197e-07,  3.90794003e-06,  9.99613106e-01,\n",
       "         2.12567997e-07,  3.77585420e-12,  5.05024800e-04,\n",
       "         2.29913428e-01,  3.67289643e-10,  1.35568998e-05,\n",
       "         7.90929366e-09,  2.55025924e-07,  6.42424891e-10,\n",
       "         1.45922215e-07,  7.69504607e-01,  2.42297974e-05,\n",
       "         3.85263193e-05,  1.42539079e-07,  5.46705472e-08,\n",
       "         3.02907961e-06,  1.84937807e-12,  1.90136462e-10,\n",
       "         1.87940791e-03,  3.54433361e-13,  4.56110809e-11,\n",
       "         1.02351648e-10,  2.75616650e-03,  1.31183793e-03,\n",
       "         6.71402595e-05,  1.93894721e-06,  3.73792641e-09,\n",
       "         4.07816107e-11,  7.70039144e-09,  5.47179001e-13,\n",
       "         4.08829770e-09,  1.72116499e-16,  3.87072241e-09,\n",
       "         1.69765080e-05,  9.41134254e-11,  4.37954848e-13,\n",
       "         1.43924803e-12,  1.34119871e-09,  3.22811356e-05,\n",
       "         5.21196810e-08,  8.68501882e-10,  1.05586505e-05,\n",
       "         9.93735731e-01,  2.98584268e-08,  1.84336168e-04,\n",
       "         1.57386153e-11,  1.69149395e-12,  3.51617871e-07,\n",
       "         2.11984670e-07,  2.53669447e-10,  3.42078025e-15,\n",
       "         1.05838774e-14,  1.05118236e-12,  5.39105869e-13,\n",
       "         1.34146021e-07,  1.04320515e-03,  5.07592013e-08,\n",
       "         8.92640829e-01,  1.04951025e-04,  3.28646471e-10,\n",
       "         5.25806759e-11,  7.30073779e-09,  1.19685812e-03,\n",
       "         6.66946789e-06,  1.04998142e-01,  1.74464798e-08,\n",
       "         1.62170807e-07,  1.76916523e-10,  7.77705554e-06,\n",
       "         8.08899131e-07,  2.61580047e-09,  8.55570370e-09,\n",
       "         4.92545604e-09,  4.46868000e-08,  3.50955332e-07],\n",
       "       [ 4.00161922e-01,  6.55872703e-01,  1.57008297e-04,\n",
       "         3.43970329e-01, -7.45115459e-01,  6.30573149e-10,\n",
       "         8.86815542e-05,  2.22912089e-09,  5.58060664e-09,\n",
       "         9.99911308e-01, -6.41547084e-01,  5.54457620e-05,\n",
       "         1.53637901e-01,  8.46276283e-01,  1.31958416e-06,\n",
       "         2.90726348e-05,  4.52930748e-01,  4.95130807e-01,\n",
       "         5.29396115e-03,  1.41868150e-05,  2.63906287e-07,\n",
       "         5.66687334e-07,  4.53879423e-02,  3.33159915e-05,\n",
       "         1.87424637e-04,  2.23046285e-07,  1.01094798e-03,\n",
       "         7.96888162e-06,  1.60035449e-06,  8.34917344e-08,\n",
       "         1.72701627e-11,  2.29205011e-09,  2.36482847e-05,\n",
       "         2.95603750e-11,  1.11161725e-07,  3.37228130e-07,\n",
       "         1.00117258e-11,  2.31388049e-06,  6.06959927e-10,\n",
       "         1.26955806e-08,  6.44274110e-07,  1.30403263e-04,\n",
       "         2.48595256e-07,  1.93385201e-08,  3.31322678e-11,\n",
       "         5.95914753e-05,  1.26222009e-03,  3.72868181e-10,\n",
       "         1.90472892e-05,  8.01796432e-06,  1.99242489e-08,\n",
       "         7.28574669e-05,  1.71057069e-09,  4.46163284e-07,\n",
       "         3.84721552e-08,  9.02786255e-01,  2.63780784e-08,\n",
       "         7.43103179e-09,  2.21586326e-14,  1.75073154e-07,\n",
       "         1.84803775e-05,  1.14201171e-09,  9.55293924e-02,\n",
       "         4.00454212e-07,  1.44196911e-11,  8.40048378e-05,\n",
       "         6.40892843e-14,  1.40460406e-06,  6.55530144e-12,\n",
       "         2.95602018e-03,  5.26444346e-04,  1.79059803e-01,\n",
       "         5.04030474e-03,  3.72802361e-07,  3.00228919e-07,\n",
       "         2.14739814e-02,  2.65613585e-06,  6.41412316e-06,\n",
       "         3.98199882e-05,  1.90023445e-06,  9.82481288e-04,\n",
       "         6.07398987e-01,  2.98911496e-03,  1.27150226e-04,\n",
       "         3.24797438e-04,  1.73221976e-01,  1.95046523e-04,\n",
       "         5.48686785e-07,  5.63949021e-03,  1.22643605e-05],\n",
       "       [ 5.67067981e-01,  4.65988879e-12,  1.59619442e-12,\n",
       "         1.00000000e+00,  6.85304776e-02,  1.57590397e-03,\n",
       "         1.44591987e-01,  3.06623156e-06,  7.96074748e-01,\n",
       "         5.77543378e-02, -7.83587217e-01,  8.76496255e-01,\n",
       "         4.99197207e-02,  4.38653380e-02,  1.56647190e-02,\n",
       "         1.40540618e-02,  5.86507394e-06,  4.79120799e-10,\n",
       "         3.49421636e-13,  1.59487035e-03,  5.36097048e-07,\n",
       "         4.10338034e-05,  1.78972392e-08,  1.81536052e-07,\n",
       "         9.98193443e-01,  1.33083086e-10,  3.16622284e-09,\n",
       "         4.58415386e-08,  8.53243591e-08,  1.63947974e-04,\n",
       "         5.24553867e-09,  1.17492531e-08,  3.29869199e-09,\n",
       "         5.09022655e-08,  6.11971151e-12,  2.77694256e-11,\n",
       "         1.63660674e-09,  8.39873672e-01,  1.12110947e-03,\n",
       "         4.55372762e-09,  1.04057649e-03,  9.93123322e-05,\n",
       "         7.60406405e-10,  8.25738523e-12,  5.94416742e-05,\n",
       "         2.52831983e-03,  1.35952786e-01,  8.48850003e-04,\n",
       "         7.09406631e-11,  7.08253386e-11,  9.38992661e-10,\n",
       "         5.88037175e-10,  2.01711439e-10,  1.58346742e-02,\n",
       "         4.31716330e-07,  2.06378150e-08,  2.54092552e-03,\n",
       "         4.07641710e-06,  2.65171147e-05,  3.42986795e-07,\n",
       "         2.63912087e-10,  4.60372213e-10,  6.45137916e-05,\n",
       "         3.59202890e-10,  2.58352333e-14,  1.07904285e-07,\n",
       "         1.22540575e-10,  5.31286848e-10,  4.33504647e-06,\n",
       "         7.12396344e-04,  3.74185248e-07,  3.94720843e-07,\n",
       "         2.20225756e-05,  6.13438811e-09,  2.58319408e-13,\n",
       "         2.24706741e-06,  3.77372383e-10,  5.25297805e-09,\n",
       "         4.43953052e-02,  4.72430450e-08,  8.56300062e-08,\n",
       "         5.24772611e-03,  1.05004574e-07,  8.83650861e-11,\n",
       "         1.51111381e-04,  5.21949939e-02,  4.66203812e-12,\n",
       "         1.14853248e-01,  7.82419980e-01,  1.42591369e-10],\n",
       "       [ 6.37421727e-01,  3.66965890e-01,  3.41212638e-02,\n",
       "         5.98912835e-01,  6.67067338e-03,  7.80445006e-08,\n",
       "         9.57381374e-09,  8.26040566e-01,  1.23890233e-04,\n",
       "         1.73835471e-01,  1.85497105e-01,  1.07898835e-07,\n",
       "         9.99954820e-01,  1.08526441e-08,  4.50852858e-05,\n",
       "         1.63822525e-10,  1.27495483e-07,  6.57915552e-06,\n",
       "         1.55548816e-12,  5.19577104e-10,  1.06414405e-10,\n",
       "         1.44615651e-05,  9.96002734e-01,  6.30283159e-09,\n",
       "         3.28212593e-07,  3.58232714e-11,  1.54495239e-09,\n",
       "         3.77076794e-03,  1.89281898e-04,  1.57745526e-05,\n",
       "         1.76639166e-08,  1.23362868e-13,  6.72129374e-08,\n",
       "         1.10285652e-12,  7.81335385e-10,  3.28482331e-13,\n",
       "         2.64627357e-14,  5.97218412e-12,  1.98493175e-12,\n",
       "         1.18151463e-12,  6.09190259e-12,  3.84136555e-17,\n",
       "         3.35667149e-13,  7.18313145e-14,  9.99999881e-01,\n",
       "         1.33812586e-17,  1.79972106e-14,  1.68451433e-10,\n",
       "         7.68591873e-16,  6.71980841e-15,  1.73559819e-10,\n",
       "         6.50740638e-13,  3.02317026e-11,  6.31057863e-16,\n",
       "         5.60988318e-21,  8.46912263e-11,  4.88535062e-18,\n",
       "         1.18274164e-15,  4.06050959e-14,  1.79417659e-09,\n",
       "         8.73059351e-12,  6.30691449e-14,  1.83824215e-16,\n",
       "         3.38916950e-11,  3.36906847e-14,  4.93839763e-17,\n",
       "         4.85483181e-16,  3.02963557e-11,  5.10782931e-13,\n",
       "         3.41597006e-05,  6.80351839e-14,  3.91218666e-04,\n",
       "         8.49466371e-14,  1.46458788e-07,  6.72514201e-04,\n",
       "         8.33744358e-12,  8.42870695e-13,  6.19926110e-10,\n",
       "         1.09157138e-01,  1.52358055e-08,  2.44630116e-09,\n",
       "         8.89585495e-01,  5.34242789e-13,  3.66860178e-07,\n",
       "         2.03586814e-09,  1.97926209e-09,  1.05766498e-11,\n",
       "         1.58648967e-04,  1.14145776e-11,  4.16706087e-07],\n",
       "       [ 1.43655658e-01,  4.15886143e-06,  9.99572814e-01,\n",
       "         4.22959856e-04, -6.90184474e-01,  1.15389781e-07,\n",
       "         1.59688845e-01,  3.72974612e-02,  5.87796603e-05,\n",
       "         8.02954853e-01, -7.43353128e-01,  9.99992013e-01,\n",
       "         5.03212914e-06,  6.21993024e-07,  1.28110628e-06,\n",
       "         1.02954994e-06,  1.39923706e-11,  7.78631879e-13,\n",
       "         1.90894015e-15,  8.46472532e-18,  3.48675620e-17,\n",
       "         8.77968716e-07,  7.26428334e-05,  9.99926567e-01,\n",
       "         3.23521287e-14,  8.56301141e-12,  3.30092399e-13,\n",
       "         5.10654088e-16,  1.54224117e-14,  2.57399813e-11,\n",
       "         3.59284915e-14,  8.27587651e-12,  3.57323492e-14,\n",
       "         1.18538939e-08,  5.26045943e-11,  1.19742389e-12,\n",
       "         2.49611026e-10,  5.36761018e-11,  4.47412662e-11,\n",
       "         9.07741271e-10,  8.00835906e-14,  1.77848449e-06,\n",
       "         2.45246801e-09,  4.69423611e-09,  2.38848361e-06,\n",
       "         1.78941875e-08,  1.58849198e-05,  6.01277437e-13,\n",
       "         9.90335703e-01,  1.04445302e-13,  3.69747366e-09,\n",
       "         7.64275665e-09,  1.01483426e-08,  1.75456216e-06,\n",
       "         5.33344835e-09,  6.17378162e-11,  6.92089897e-09,\n",
       "         2.47046217e-10,  8.77497239e-13,  9.59634688e-03,\n",
       "         3.35712393e-05,  1.08588284e-10,  7.23268559e-14,\n",
       "         2.97431075e-06,  2.96762208e-13,  4.67609512e-13,\n",
       "         4.72867578e-11,  4.91122324e-15,  9.48755314e-06,\n",
       "         2.26544312e-08,  5.30949798e-11,  5.87642565e-12,\n",
       "         9.99686003e-01,  2.70866889e-14,  9.73541447e-16,\n",
       "         2.99499364e-14,  2.00624066e-12,  2.48890981e-04,\n",
       "         2.20707619e-11,  1.83165969e-13,  1.04242135e-08,\n",
       "         5.22473002e-11,  6.11801879e-05,  5.07803261e-12,\n",
       "         8.32145186e-10,  3.92433321e-06,  5.29966280e-15,\n",
       "         6.77477701e-08,  1.15433782e-11,  2.34988092e-12],\n",
       "       [ 7.33989418e-01,  4.93423364e-08,  1.53034359e-01,\n",
       "         8.46965611e-01,  8.33048344e-01,  2.08779126e-01,\n",
       "         1.05953760e-01,  6.56323075e-01,  2.89436821e-02,\n",
       "         2.85260256e-07, -7.68011576e-03,  4.64304954e-01,\n",
       "         4.76753533e-01,  4.26471531e-02,  2.44061113e-03,\n",
       "         1.38537046e-02,  4.06802911e-08,  9.99920607e-01,\n",
       "         2.09529321e-11,  4.62555411e-11,  1.23776019e-07,\n",
       "         2.65611903e-12,  1.36376244e-09,  1.94841755e-06,\n",
       "         9.94221864e-07,  1.22118289e-08,  9.56946522e-09,\n",
       "         6.30426730e-05,  6.96580310e-06,  6.33086938e-06,\n",
       "         1.04609410e-06,  7.79862876e-06,  2.40843612e-09,\n",
       "         1.13106822e-08,  8.38848546e-10,  4.37279439e-08,\n",
       "         7.49975637e-09,  9.71244276e-07,  1.98943328e-09,\n",
       "         2.31022618e-10,  1.35717210e-06,  1.16181863e-10,\n",
       "         3.91234993e-04,  2.70098202e-12,  5.27449991e-14,\n",
       "         1.06694529e-08,  1.39793087e-07,  3.90919240e-07,\n",
       "         1.74489578e-09,  3.03799084e-07,  3.13862103e-07,\n",
       "         3.62073371e-10,  9.38235978e-09,  9.64424166e-11,\n",
       "         5.41455756e-06,  9.31884733e-06,  9.99275148e-01,\n",
       "         2.30088466e-11,  8.41558434e-10,  4.27209712e-10,\n",
       "         4.78661466e-09,  1.70974115e-08,  1.22729489e-08,\n",
       "         1.87841404e-04,  2.20565504e-08,  9.79605108e-09,\n",
       "         1.15264884e-04,  3.26316558e-06,  1.95149192e-11,\n",
       "         5.34012976e-08,  9.53064682e-06,  3.10122065e-04,\n",
       "         3.78860103e-04,  7.47294937e-09,  1.00518455e-05,\n",
       "         2.91028246e-03,  8.15782100e-02,  1.03717124e-04,\n",
       "         7.77816924e-04,  6.79945344e-08,  1.76255867e-06,\n",
       "         6.86600688e-05,  1.43021496e-03,  8.11757818e-02,\n",
       "         7.73928285e-01,  6.32855006e-07,  1.11125148e-04,\n",
       "         2.43052909e-06,  1.28319738e-02,  4.43704389e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat(data_t, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert a column of raw data to appropriate format for discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a column of data to appropriate format for discriminator\n",
    "\n",
    "def _transform_continuous(column_transform_info, data):\n",
    "    column_name = data.columns[0]\n",
    "    flattened_column = data[column_name].to_numpy().flatten()\n",
    "    data = data.assign(**{column_name: flattened_column})\n",
    "    gm = column_transform_info.transform\n",
    "    transformed = gm.transform(data)\n",
    "\n",
    "    #  Converts the transformed data to the appropriate output format.\n",
    "    #  The first column (ending in '.normalized') stays the same,\n",
    "    #  but the lable encoded column (ending in '.component') is one hot encoded.\n",
    "    output = np.zeros((len(transformed), column_transform_info.output_dimensions))\n",
    "    output[:, 0] = transformed[f'{column_name}.normalized'].to_numpy()\n",
    "    index = transformed[f'{column_name}.component'].to_numpy().astype(int)\n",
    "    output[np.arange(index.size), index + 1] = 1.0\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'injury_claim'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_transform_info = column_transform_info_list[0]\n",
    "column_name = column_transform_info.column_name\n",
    "data = raw_data[[column_name]]\n",
    "column_name = data.columns[0]\n",
    "column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>injury_claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>17440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>18080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>5220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     injury_claim\n",
       "0            6510\n",
       "1             780\n",
       "2            7700\n",
       "3            6340\n",
       "4            1300\n",
       "..            ...\n",
       "995         17440\n",
       "996         18080\n",
       "997          7500\n",
       "998          5220\n",
       "999           460\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       6510\n",
       "1        780\n",
       "2       7700\n",
       "3       6340\n",
       "4       1300\n",
       "       ...  \n",
       "995    17440\n",
       "996    18080\n",
       "997     7500\n",
       "998     5220\n",
       "999      460\n",
       "Name: injury_claim, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[column_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6510,   780,  7700,  6340,  1300,  6410, 21450,  9380,  2770,\n",
       "        4700,  7910, 17680,  4710,  1120,  4200, 10520,  5790, 14160,\n",
       "        6630,  6040,     0,     0, 17880,  8180,  7080, 16500,  1640,\n",
       "        1040,  7760, 14100, 12600,  7460,  3310, 14020, 10800, 10620,\n",
       "        6020,  1230, 12460, 10940,  8000, 16180,  5740,  5680, 11280,\n",
       "        6890,     0,  6280,   810, 15320, 16360,  1320,   430, 12820,\n",
       "         480, 15780,     0,   300,  7310, 11440, 15440,  7380,  5630,\n",
       "       11420,  6570, 13720, 13800,     0, 12460,   860, 12420,  6810,\n",
       "        3010,  9520,  9540, 11380, 14900, 10860,  1240, 14440, 10160,\n",
       "         660,   750,  1180,  5540,  5830, 11400, 11680,   940,     0,\n",
       "       10300,  8940,   590,  5890, 17040,  1260,  6630,  7210,   900,\n",
       "         700, 15860, 10560,     0,   330, 15580,   480,  6650,  7420,\n",
       "       10860,  5540,  7470, 14000, 14740, 14430,  1180,  4770,  9320,\n",
       "        6400, 18000, 13240, 13860, 12760,     0,  8570,  7000,  3300,\n",
       "        5760,   330, 10640,  4970, 14120,  6150,  8500,  4680, 17360,\n",
       "       13840,   410,  6550, 13840, 12260,  9460,   470,  1890,  7080,\n",
       "        5070,  7640, 12800,  4730,  8960, 17280,  7520, 10680,  9780,\n",
       "       10540,  9040,     0,  7210,  1300, 13040,  1240,   560, 11700,\n",
       "       13240, 10790, 18180, 11160, 12960, 12800,   660,   670, 11940,\n",
       "        6700,  4990, 11100,   610, 15920,  8560, 11380, 13100,   450,\n",
       "       10220, 16800, 16540, 14880,  5490,  8060,  2250,  1100, 13440,\n",
       "       18520,   980,  5610,  5550,  1280,  5020,  6960,   530,   650,\n",
       "        5940,   280,   960,  7670,   740,  7150,  4240,  5440,  5980,\n",
       "        7200,  7230,  1760,  1020,  1180,  8580,  9720,  6780,  7370,\n",
       "        5260,  1440, 12780,  9260, 11160,  2810,  8920,  6340, 12980,\n",
       "        7350,  6840, 12990,  6560, 14460,  4880,  3050,  6910, 14500,\n",
       "        5360, 12760,  4570, 14300,  6460,  3530,  5350,  7370,   630,\n",
       "       10900,   640,  7540,  6460, 15180,  1180,  6410,  5040,  7350,\n",
       "         680,  5960,  5750,  9840, 10100,  6410,   660,  5310,   350,\n",
       "        5900,  7060,  5590,  5240,  1060, 11840, 15660,  4610, 12540,\n",
       "       17060,   560, 11040, 11940, 10820,  4170,  7120, 10980,  5850,\n",
       "       14180,  7760,   860,  1240, 11980, 13260, 12780,  5810,   640,\n",
       "        7420,  1460,  8560,  5730, 10540, 15540,  5340, 12020,  7710,\n",
       "         600,  1080,  7080,  1280, 14420, 17460,  1260, 13160,  4080,\n",
       "        4800,  5910, 14080,  4570,  7340,  2850,  3500, 13600, 13000,\n",
       "        7550, 15100,  5360,  6340, 12380, 13420,  6360,  3280,  9820,\n",
       "       10080, 17680, 12100,  5980,  9420,  5060,  9920,  7060,   940,\n",
       "         580,     0,  7250,  4920,  7810,  8710,  4580, 12960, 12800,\n",
       "           0,   960, 16650, 11820,  6580, 10540, 12300, 14840, 12980,\n",
       "        7180,  5220,  6500,  6720, 11500, 11460, 10840, 20700,  6170,\n",
       "       15620,  9360,   450,     0,   620,   360,   280,  6000,  4450,\n",
       "       15560, 11680,  4010, 13520,   680,  5190,  4860,  6620,  9100,\n",
       "        4420, 10160,  4420, 11440,  5550,  6270, 18220,  5460, 16710,\n",
       "        6940, 11420,  6770,  9680,  5720,  5170, 10920,  4770,   580,\n",
       "        6110, 14980,   580, 12820,  7090,  9180,  8160,  7530,  7680,\n",
       "       15960,  9640,  2200,  7860,   290,  1300,   620, 11580,  7880,\n",
       "         780,  5570,  8930, 11120,  1000, 14740,  6930, 13520, 14040,\n",
       "        6060,  6480,  6080,  5820,  6730,  8710,  5570,  5670,  9880,\n",
       "        6130, 11700,  6660,  7340,  4650,   640,   580,   590,  6370,\n",
       "       13660,  6400,   580,   740,  6090,  4940, 12500, 12300,  6990,\n",
       "        6230, 14000,   780,  6750,  4430, 17300,   680, 13300,  8630,\n",
       "       15900,  6930,  9920,  5970, 15380,  6850,  8140, 10620,  3510,\n",
       "        9600,  5910,  5830,  7180, 15080,  1180,   590,  5590,  6380,\n",
       "        7270,   630, 19020, 12700, 12580,  6630, 16300, 15000,  8780,\n",
       "        5370, 12660, 11960, 11600,   250,  4510, 11580, 10300, 12820,\n",
       "       13380,   520,  6620,  5780, 13340,  7890,  9960,  7040,  8580,\n",
       "       11960, 12740,  5930,  9680,  6160,  6180,  8900,   820, 11760,\n",
       "       11940,  5050,  6500,  3570, 14660,  4780,   640, 14000, 16020,\n",
       "        4340,  5360,   480,   530,  7170,   300,  6330,  6870, 15040,\n",
       "       14720,  6590,  1240,  5690,  6550,  5780,  6140,   940, 13480,\n",
       "        6930,  1660,  8740,  5670,     0, 15280, 13720, 13800,  1440,\n",
       "       12220,  4250, 14400,   840,   630,  8340, 14060,   900,   860,\n",
       "        2730,  4880,  3900, 16820,  6840,  5530, 11540, 16620, 10860,\n",
       "        5380, 16920,  6970,  3640,  4690, 14380,  7530,  9480,  7110,\n",
       "       13880,  5000,  7860,  6420, 12240,  6920, 13080, 12380,   670,\n",
       "        1020,   510,  7240, 14180,  6510,     0,  7270,  6290,  7690,\n",
       "        7420,     0,   500,   500,  6050,  6880,  4370,  7120, 10000,\n",
       "           0,  5970,  6860,  5750,   870, 15420,  6600,  9980,  6730,\n",
       "       11180,  6630,   490, 14140,  7470,  4060, 10060,  4280,  4070,\n",
       "        6300,   400,  7180,   560, 15500, 12140,  1100, 15980, 11000,\n",
       "       16040,  9760,  5380,  4530,  9880,   520,     0,   670,  5080,\n",
       "        5190,  8150,     0,  5660,  9440,  9720,  5710, 14080,  6830,\n",
       "         460,  6600,     0,  7770, 12500, 16560,  4030,  9500,   780,\n",
       "       11880,  6690,  8720,  6280, 11900,  5940,  7580,  6310,  5240,\n",
       "       17400,  4200,  5850, 11040,  8180, 10700,  4040,  3720,   480,\n",
       "         840, 10540,     0, 13860,  4060,  6720,   440,   550,  4270,\n",
       "        3660,  5000,   640, 13700,  6240,  5730,  5770,  8080,  1200,\n",
       "        9650,     0,   300,  4300,  5010,   480, 11460, 14880,  3530,\n",
       "         480,  4630,  3780, 11700, 13220,  7510, 13100,  5710,  7020,\n",
       "         490,  5540,  4580,  9900,  5540,  4990, 12480, 16280,  1300,\n",
       "       11160,  1060, 17180,   790,  6720,  6440,   480, 15660, 14940,\n",
       "       10060,  4420,  6060,  7120, 16160,  5070, 11380,  8640,  5280,\n",
       "        9200,  1400, 13520,  6800, 13000, 13020,  6060,  6770,  2930,\n",
       "        6950,  9880, 16460,  1460,  6390,  4830,  9220, 14380, 17580,\n",
       "        5340,  9460, 14920,  8060,  5810, 12400, 13500, 11920, 12780,\n",
       "        5000, 12360,  5870,  7050, 17370,  5260,  8400,  6330,  8840,\n",
       "        3520,    10,  6260,  6340,  5040,  6740,  8980, 11560,   680,\n",
       "         460,  3260,  7700, 10740,  3160,  8280,  7740,  1060,  4770,\n",
       "        4200,  5770,  4680,  5550, 16860,  3070, 11320,   660,  3480,\n",
       "        7950,  5600, 16280,   900,  4800, 10440, 12300, 15640, 13800,\n",
       "        6340,   520,  5310,   640, 14580,  7070,  5470, 13600,   820,\n",
       "        5590,   720,  8200, 12120, 15280, 10600,  5210,  5900, 14940,\n",
       "       12100,  7720,  5550, 12560,   760, 11300,  1120,   900, 21330,\n",
       "         540,  9340, 10320,   600,  5430,   860,  6870,  7960,  6240,\n",
       "        5270,  7620, 12980,   570,  8630,  4680,  7040,  7590,  5790,\n",
       "        5490,  6620, 10680,  8500,  8900, 10700,  8240,  6780,  7420,\n",
       "        5270, 13640,  7100, 11860,  6690,  3710, 15080,   420,  5850,\n",
       "        7680,  6610,  4420,   770, 10240,  5440,  9760,  6730,  3340,\n",
       "       15580,     0, 10220, 13280,  6860,   640, 12120, 10240,  9500,\n",
       "        5390,   220,  1380,  1000, 11040,   660, 11760,     0,   470,\n",
       "        6940,  4050,  5000, 11220,  8410,  6430,  6440, 16180,   500,\n",
       "        3070,  3720, 14540,  3880,  7980, 14560,     0,   400, 10440,\n",
       "       12660, 13820,  8040,  5200,   560, 13780,  5940,   430,  8320,\n",
       "        6790,   420, 10000, 13200,  6140,  5140,  5420,  5820, 13520,\n",
       "        5340, 14360,  8530, 11100,   860,  8520,   780, 15700,  7870,\n",
       "       15120,  5300,  4840, 13520, 11360,   940,  5770, 14920,   420,\n",
       "        5020,  9020, 15120, 15660,  9600,   600, 11440,  1380, 12320,\n",
       "         960,   390,  9040,  6290,  5420,  5180,   600, 13480, 13560,\n",
       "        5540,  9820, 15120,  6050, 14080,  4440, 15380,  9920,  7470,\n",
       "        6110,  5190,   430,  5710,  7690, 15400,  9280, 12140,  5920,\n",
       "        3810,     0,  3670,  6020,   540, 17440, 18080,  7500,  5220,\n",
       "         460])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_column = data[column_name].to_numpy().flatten()\n",
    "flattened_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>injury_claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>17440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>18080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>5220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     injury_claim\n",
       "0            6510\n",
       "1             780\n",
       "2            7700\n",
       "3            6340\n",
       "4            1300\n",
       "..            ...\n",
       "995         17440\n",
       "996         18080\n",
       "997          7500\n",
       "998          5220\n",
       "999           460\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.assign(**{column_name: flattened_column})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>injury_claim.normalized</th>\n",
       "      <th>injury_claim.component</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.090276</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.303125</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059869</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.189583</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.427383</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.480425</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.267352</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-0.140459</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.091881</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     injury_claim.normalized  injury_claim.component\n",
       "0                   0.090276                     2.0\n",
       "1                   0.015343                     0.0\n",
       "2                   0.303125                     2.0\n",
       "3                   0.059869                     2.0\n",
       "4                   0.189583                     0.0\n",
       "..                       ...                     ...\n",
       "995                 0.427383                     1.0\n",
       "996                 0.480425                     1.0\n",
       "997                 0.267352                     2.0\n",
       "998                -0.140459                     2.0\n",
       "999                -0.091881                     0.0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Converts the transformed data to the appropriate output format.\n",
    "#  The first column (ending in '.normalized') stays the same,\n",
    "#  but the lable encoded column (ending in '.component') is one hot encoded.\n",
    "gm = column_transform_info.transform\n",
    "transformed = gm.transform(data)\n",
    "transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_transform_info.output_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "output = np.zeros((len(transformed), column_transform_info.output_dimensions))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0902761 ,  0.015343  ,  0.30312498,  0.05986911,  0.18958275,\n",
       "        0.07238964,  0.75972111, -0.24060727, -0.78842587, -0.23346884,\n",
       "        0.34068655,  0.44727388, -0.2316802 ,  0.12926899, -0.32290115,\n",
       "       -0.14612721, -0.03850642,  0.15554597,  0.11173985, -0.51741727,\n",
       "       -0.24601662, -0.24601662,  0.46384933,  0.38897999,  0.19222892,\n",
       "        0.34947873,  0.30350874,  0.10246288,  0.31385686,  0.15057334,\n",
       "        0.02625747,  0.26019747, -0.48209065,  0.14394316, -0.12292158,\n",
       "       -0.13783948,  0.00263244,  0.1661274 ,  0.01465465, -0.11131876,\n",
       "        0.35678436,  0.32295801, -0.04744965, -0.05818153, -0.0831405 ,\n",
       "        0.15824465, -0.24601662,  0.04913724,  0.02539529,  0.25168358,\n",
       "        0.33787592,  0.19628428, -0.10193375,  0.04449046, -0.08517993,\n",
       "        0.28980711, -0.24601662, -0.14549369,  0.23336778, -0.06988014,\n",
       "        0.26162885,  0.24588831, -0.06712476, -0.07153768,  0.10100797,\n",
       "        0.11907998,  0.12571016, -0.24601662,  0.01465465,  0.04214912,\n",
       "        0.01133956,  0.14393548, -0.53575003, -0.22900445, -0.22734691,\n",
       "       -0.07485277,  0.21687514, -0.11794894,  0.16947816,  0.1787516 ,\n",
       "       -0.17596302, -0.02486617,  0.00529071,  0.14937358, -0.08322257,\n",
       "       -0.03135184, -0.07319523, -0.0499896 ,  0.06895523, -0.24601662,\n",
       "       -0.1643602 , -0.27707326, -0.04832152, -0.02061996,  0.39423245,\n",
       "        0.17617969,  0.11173985,  0.21548132,  0.05555217, -0.01146311,\n",
       "        0.29643729, -0.14281212, -0.24601662, -0.1354414 ,  0.27323166,\n",
       "       -0.08517993,  0.11531714,  0.25304289, -0.11794894, -0.08322257,\n",
       "        0.26198612,  0.14228561,  0.20361478,  0.17792283,  0.14937358,\n",
       "       -0.62267138, -0.2455799 ,  0.07060099,  0.4737946 ,  0.07929891,\n",
       "        0.1306828 ,  0.03951783, -0.24601662, -0.30773784,  0.17791976,\n",
       "       -0.48387929, -0.04387236, -0.1354414 , -0.13618194, -0.1851754 ,\n",
       "        0.15223088,  0.02588484,  0.44621667, -0.23704613,  0.42075316,\n",
       "        0.12902525, -0.10863528,  0.09743068,  0.12902525, -0.0019208 ,\n",
       "       -0.23397709, -0.0885307 ,  0.38727785,  0.19222892, -0.16728894,\n",
       "       -0.38481368,  0.04283292, -0.2281029 ,  0.52849439,  0.41412298,\n",
       "        0.27092935, -0.13286685,  0.67516336, -0.14446966,  0.54280355,\n",
       "       -0.24601662,  0.21548132,  0.18958275,  0.06272346,  0.16947816,\n",
       "       -0.05837382, -0.04833206,  0.07929891, -0.12375035,  0.48871251,\n",
       "       -0.09308577,  0.05609328,  0.04283292, -0.02486617, -0.02151541,\n",
       "       -0.02844152,  0.12426037, -0.60443838, -0.0980584 , -0.04161999,\n",
       "        0.30140993,  0.45694854, -0.07485277,  0.06769609, -0.09523223,\n",
       "       -0.17099038,  0.37434191,  0.35279382,  0.21521759, -0.0921658 ,\n",
       "       -0.35000524,  0.50790537,  0.12256746,  0.09587436,  0.51689077,\n",
       "        0.08235829, -0.07070205, -0.08143393,  0.18288122, -0.17623217,\n",
       "        0.17076517, -0.06842611, -0.02821694, -0.01167673, -0.15219522,\n",
       "        0.07565676,  0.29775904,  0.00193994,  0.20474945, -0.31574656,\n",
       "       -0.10110903, -0.52238991,  0.21369268,  0.21905861,  0.34371791,\n",
       "        0.09576135,  0.14937358, -0.30690907, -0.212429  ,  0.13856954,\n",
       "        0.24409966, -0.13330466,  0.23649345,  0.04117537, -0.25055254,\n",
       "       -0.09308577,  0.69554818,  0.5213398 ,  0.05986911,  0.05775082,\n",
       "        0.24052237,  0.14930142,  0.05857959,  0.09921933,  0.18040915,\n",
       "       -0.20127321, -0.52859544,  0.16182194,  0.18372424, -0.1154182 ,\n",
       "        0.03951783, -0.25672124,  0.16714879,  0.08133287, -0.44274043,\n",
       "       -0.11720685,  0.24409966, -0.03491847, -0.11463385, -0.0315677 ,\n",
       "        0.27450664,  0.08133287,  0.24008077,  0.14937358,  0.07238964,\n",
       "       -0.17265488,  0.24052237, -0.01816464, -0.00809944, -0.045661  ,\n",
       "       -0.20248374, -0.18093565,  0.07238964, -0.02486617, -0.12436143,\n",
       "       -0.12873987, -0.01883131,  0.18865163, -0.07427934, -0.13688195,\n",
       "        0.1091644 , -0.03672924,  0.27986184, -0.24956666,  0.02128483,\n",
       "        0.39588999, -0.05837382, -0.10303104, -0.02844152, -0.12126403,\n",
       "       -0.32826708,  0.19938351, -0.10800367, -0.02777454,  0.15720352,\n",
       "        0.31385686,  0.04214912,  0.16947816, -0.02512643,  0.08095645,\n",
       "        0.04117537, -0.03492913, -0.0315677 ,  0.25304289,  0.24319498,\n",
       "        0.45694854, -0.0492383 , -0.14446966,  0.26991657, -0.11899549,\n",
       "       -0.02181134, -0.37901227, -0.04497076,  0.11586593,  0.19222892,\n",
       "        0.18288122,  0.17709406,  0.42904089,  0.17617969,  0.07266873,\n",
       "       -0.3443649 , -0.21558238, -0.01704267,  0.14891579, -0.25672124,\n",
       "       -0.40967685, -0.56436837, -0.44810637,  0.10913471,  0.05940837,\n",
       "        0.27629529,  0.23345059, -0.1154182 ,  0.05986911,  0.00802447,\n",
       "        0.09421681,  0.06344641, -0.48745659, -0.20414128, -0.1825932 ,\n",
       "        0.44727388, -0.01518116, -0.00452214, -0.23729218, -0.16907758,\n",
       "       -0.19585356,  0.18865163,  0.06895523, -0.05167229, -0.24601662,\n",
       "        0.22263591, -0.19411863,  0.32280009, -0.29613502, -0.2549326 ,\n",
       "        0.05609328,  0.04283292, -0.24601662,  0.07565676,  0.36191032,\n",
       "       -0.03838679, -0.47266356, -0.14446966,  0.00139429,  0.2119025 ,\n",
       "        0.05775082, -0.42293721, -0.14045925,  0.08848745,  0.12783767,\n",
       "       -0.0649075 , -0.06822259, -0.11960649,  0.69756317,  0.02946213,\n",
       "        0.27654675, -0.24226481, -0.09523223, -0.24601662, -0.03826923,\n",
       "       -0.1253891 , -0.15219522, -0.00094485, -0.27818499,  0.27157412,\n",
       "       -0.0499896 , -0.68565809,  0.10250454, -0.01816464, -0.14582518,\n",
       "       -0.20485051,  0.1099512 , -0.2638129 , -0.28355093, -0.17596302,\n",
       "       -0.28355093, -0.06988014, -0.08143393,  0.04734859,  0.4920276 ,\n",
       "       -0.09753174,  0.36688295,  0.16718788, -0.07153768,  0.1367809 ,\n",
       "       -0.21574409, -0.05102694, -0.14940248, -0.11297631, -0.22094832,\n",
       "       -0.05167229,  0.01873025,  0.22350532, -0.05167229,  0.04449046,\n",
       "        0.19401757, -0.25718272,  0.3854027 ,  0.272718  ,  0.29954769,\n",
       "        0.30472502,  0.65012232,  0.49115155, -0.36658068, -0.14884446,\n",
       "        0.18958275, -0.03826923, -0.05827732,  0.33532061,  0.015343  ,\n",
       "       -0.07785663, -0.27790203, -0.09640086,  0.08905982,  0.20361478,\n",
       "        0.16539923,  0.10250454,  0.1456007 ,  0.00978702, -0.48095129,\n",
       "        0.01336432, -0.03314048,  0.12962631,  0.48377823, -0.07785663,\n",
       "       -0.05997017, -0.19916865,  0.02230755, -0.04833206,  0.11710579,\n",
       "        0.23873372, -0.24241207, -0.0315677 , -0.05167229, -0.04832152,\n",
       "        0.06523505,  0.11410735,  0.07060099, -0.05167229,  0.00193994,\n",
       "        0.01515296, -0.19054134,  0.01796974,  0.00139429,  0.17613111,\n",
       "        0.04019401,  0.14228561,  0.015343  ,  0.1332036 , -0.28176229,\n",
       "        0.41578053, -0.01816464,  0.08427154,  0.46946907,  0.29975238,\n",
       "        0.16539923, -0.19585356, -0.00631079,  0.25665622,  0.15109006,\n",
       "        0.38182541, -0.13783948, -0.44631773, -0.22237427, -0.01704267,\n",
       "       -0.03135184,  0.21011538,  0.23179304,  0.14937358, -0.04832152,\n",
       "       -0.07427934,  0.0670237 ,  0.2262132 , -0.03491847,  0.5583294 ,\n",
       "        0.03454519,  0.02459992,  0.11173985,  0.33290328,  0.22516286,\n",
       "        0.49629876, -0.11362956,  0.0312301 , -0.02678397, -0.05661978,\n",
       "       -0.16224751, -0.26745312, -0.05827732, -0.1643602 ,  0.04449046,\n",
       "        0.09090172, -0.07177687, -0.46934847, -0.04029507,  0.08758663,\n",
       "       -0.36409437, -0.19253847,  0.18507434,  0.46052584, -0.02678397,\n",
       "        0.03786028, -0.01346538, -0.21574409, -0.50747201,  0.03125078,\n",
       "       -0.28038835,  0.02874606, -0.04335942, -0.02844152, -0.17086623,\n",
       "        0.08848745, -0.43558585,  0.1969846 , -0.21915967, -0.0315677 ,\n",
       "        0.14228561,  0.30969765, -0.2978601 , -0.1154182 , -0.08517993,\n",
       "       -0.06842611,  0.20832674, -0.14549369,  0.05808047, -0.44862916,\n",
       "        0.22847795,  0.20195723,  0.10458527,  0.16947816, -0.05639288,\n",
       "        0.09743068, -0.53896536,  0.02409619,  0.06895523,  0.09918945,\n",
       "        0.16539923,  0.31021027,  0.48914417, -0.05997017, -0.24601662,\n",
       "        0.24836849,  0.11907998,  0.12571016,  0.23649345, -0.00523589,\n",
       "       -0.31395792,  0.17543651,  0.03544759, -0.03491847,  0.41759833,\n",
       "        0.14725825,  0.05555217,  0.04214912,  0.66874206, -0.20127321,\n",
       "       -0.37656053,  0.37599945,  0.14930142, -0.08501122, -0.06159241,\n",
       "        0.359424  , -0.11794894, -0.11184091,  0.38428718,  0.17255382,\n",
       "       -0.42306533, -0.23525749,  0.17377897,  0.272718  , -0.23231954,\n",
       "        0.19759486,  0.13234034, -0.17980946, -0.36658068,  0.07417828,\n",
       "       -0.00357834,  0.16361059,  0.06603855,  0.00802447, -0.02151541,\n",
       "        0.09576135, -0.07512764,  0.22084726,  0.15720352,  0.0902761 ,\n",
       "       -0.24601662,  0.2262132 ,  0.05092588,  0.30133633, -0.40304667,\n",
       "       -0.24601662, -0.0784784 , -0.0784784 , -0.5165885 ,  0.156456  ,\n",
       "       -0.29249416,  0.19938351, -0.18922338, -0.24601662, -0.00631079,\n",
       "        0.15287871, -0.045661  ,  0.04549988,  0.2599713 ,  0.10637391,\n",
       "       -0.19088092,  0.12962631, -0.09142822,  0.11173985, -0.08182917,\n",
       "        0.15388843,  0.26198612, -0.34794219, -0.18425074, -0.30859198,\n",
       "       -0.34615355,  0.05271453, -0.11198605, -0.42293721, -0.05837382,\n",
       "        0.26660148, -0.01186607,  0.12256746,  0.30638256, -0.10634613,\n",
       "        0.3113552 , -0.20911391, -0.11184091, -0.26387583, -0.19916865,\n",
       "       -0.07177687, -0.24601662, -0.02151541, -0.16550029, -0.14582518,\n",
       "       -0.34254628, -0.24601662, -0.06175882, -0.23563463, -0.212429  ,\n",
       "       -0.05281559,  0.14891579,  0.14751277, -0.09188146,  0.10637391,\n",
       "       -0.24601662, -0.37403964,  0.01796974,  0.35445137, -0.35330813,\n",
       "       -0.230662  ,  0.015343  , -0.03341415,  0.12247173, -0.29530625,\n",
       "        0.04913724, -0.03175661, -0.01167673,  0.28166123,  0.05450318,\n",
       "       -0.58371907,  0.42406825, -0.32290115, -0.02777454, -0.10303104,\n",
       "       -0.34005997, -0.1312093 , -0.35151948, -0.40875616, -0.08517993,\n",
       "        0.03544759, -0.14446966, -0.24601662,  0.1306828 , -0.34794219,\n",
       "        0.12783767, -0.09858299, -0.06172458, -0.31038062, -0.41948803,\n",
       "       -0.17980946, -0.0315677 ,  0.11742244,  0.04198265, -0.0492383 ,\n",
       "       -0.04208371, -0.34834769,  0.15607511, -0.21823041, -0.24601662,\n",
       "       -0.14549369, -0.30501469, -0.17802081, -0.08517993, -0.06822259,\n",
       "        0.21521759, -0.44274043, -0.08517993, -0.24598936, -0.39802428,\n",
       "       -0.04833206,  0.07764136,  0.26914071,  0.06769609, -0.05281559,\n",
       "        0.18149705, -0.08182917, -0.08322257, -0.2549326 , -0.1975111 ,\n",
       "       -0.08322257, -0.18159811,  0.0163122 ,  0.33124574,  0.18958275,\n",
       "       -0.09308577,  0.1091644 ,  0.40583526,  0.01869376,  0.12783767,\n",
       "        0.07775557, -0.08517993,  0.27986184,  0.22019023, -0.18425074,\n",
       "       -0.28355093,  0.00978702,  0.19938351,  0.32130047, -0.16728894,\n",
       "       -0.07485277, -0.30193643, -0.12972737, -0.25552517,  0.22309039,\n",
       "        0.10250454,  0.14214683,  0.05940837,  0.06106591,  0.00978702,\n",
       "        0.1367809 , -0.5500592 , -0.44199898, -0.19916865,  0.34616364,\n",
       "        0.24319498,  0.06881234, -0.21021644,  0.57499918,  0.17377897,\n",
       "        0.43898616, -0.11899549,  0.61792669,  0.21853268,  0.36751624,\n",
       "       -0.03492913,  0.00968202,  0.10084699, -0.03009906,  0.04117537,\n",
       "       -0.17980946,  0.00636693, -0.02419725,  0.18686299,  0.42158194,\n",
       "       -0.13330466,  0.42833021,  0.05808047, -0.28536098, -0.44452908,\n",
       "       -0.24266586,  0.04555995,  0.05986911, -0.17265488,  0.13141496,\n",
       "        0.53207168, -0.05993487, -0.01816464, -0.09188146, -0.49103388,\n",
       "       -0.37984104, -0.12789421, -0.50892034, -0.33177224,  0.31027956,\n",
       "        0.1091644 , -0.22094832, -0.32290115, -0.04208371, -0.23704613,\n",
       "       -0.08143393,  0.37931454, -0.52501815, -0.07982541, -0.02486617,\n",
       "       -0.72958303,  0.34784113, -0.0724907 ,  0.33124574,  0.05555217,\n",
       "       -0.21558238, -0.15275739,  0.00139429,  0.2782043 ,  0.12571016,\n",
       "        0.05986911, -0.07177687, -0.57791767, -0.0315677 ,  0.19035442,\n",
       "        0.19044028, -0.09574309,  0.10913471,  0.02874606, -0.07427934,\n",
       "       -0.00476159,  0.39255728, -0.01352361,  0.24836849,  0.82183234,\n",
       "       -0.14224789, -0.01883131,  0.22019023, -0.01518116,  0.30670227,\n",
       "       -0.08143393,  0.02294238,  0.00864147, -0.08148295,  0.12926899,\n",
       "        0.05555217,  0.74977584, -0.06507535, -0.24392236, -0.16270266,\n",
       "       -0.04497076, -0.10289768,  0.04214912,  0.15466736,  0.34962978,\n",
       "        0.04198265, -0.13151602, -0.38647122,  0.05775082, -0.05502305,\n",
       "       -0.3027652 , -0.23704613,  0.18507434,  0.28344987, -0.03850642,\n",
       "       -0.0921658 ,  0.1099512 , -0.13286685,  0.44621667, -0.28038835,\n",
       "       -0.1312093 ,  0.39971187,  0.13856954,  0.25304289, -0.13151602,\n",
       "        0.1124498 ,  0.19580622, -0.0350717 ,  0.12247173, -0.4105448 ,\n",
       "        0.23179304, -0.10528452, -0.02777454,  0.29954769,  0.10816256,\n",
       "       -0.28355093,  0.01199224, -0.16933284, -0.10110903, -0.20911391,\n",
       "        0.12962631, -0.47672471,  0.27323166, -0.24601662, -0.17099038,\n",
       "        0.082614  ,  0.15287871, -0.0315677 , -0.01352361,  0.75744108,\n",
       "       -0.230662  , -0.11005226, -0.17229981,  0.21638887,  0.08905982,\n",
       "       -0.10303104, -0.02486617, -0.04335942, -0.24601662, -0.0885307 ,\n",
       "        0.16718788, -0.34973084, -0.17980946, -0.08811313, -0.3209982 ,\n",
       "        0.07596693,  0.07775557,  0.32295801, -0.0784784 , -0.52501815,\n",
       "       -0.40875616,  0.18703933, -0.38013782,  0.35320707,  0.18869687,\n",
       "       -0.24601662, -0.11198605, -0.15275739,  0.0312301 ,  0.12736771,\n",
       "        0.36393895, -0.14403654, -0.05837382,  0.12405262, -0.01167673,\n",
       "       -0.10193375,  0.41402104,  0.14035819, -0.10528452, -0.18922338,\n",
       "        0.07598382,  0.02409619, -0.15476842, -0.10468632, -0.03314048,\n",
       "        0.10250454, -0.11899549,  0.17212142, -0.31105293, -0.0980584 ,\n",
       "        0.04214912, -0.3118817 ,  0.015343  ,  0.28317693,  0.33353196,\n",
       "        0.23510813, -0.12615008, -0.2084278 ,  0.10250454, -0.07651032,\n",
       "        0.06895523, -0.04208371,  0.21853268, -0.10528452, -0.17623217,\n",
       "       -0.27044308,  0.23510813,  0.27986184, -0.22237427, -0.04497076,\n",
       "       -0.06988014,  0.21638887,  0.00305184,  0.07565676, -0.11533681,\n",
       "       -0.26878553,  0.05092588, -0.10468632, -0.14761383, -0.04497076,\n",
       "        0.09918945,  0.10581962, -0.08322257, -0.20414128,  0.23510813,\n",
       "        0.00799838,  0.14891579, -0.27997364,  0.25665622, -0.19585356,\n",
       "        0.26198612,  0.01873025, -0.14582518, -0.10193375, -0.54476677,\n",
       "        0.30133633,  0.25831376, -0.24889499, -0.01186607, -0.01525402,\n",
       "       -0.39265834, -0.24601662, -0.41769939,  0.00263244, -0.06507535,\n",
       "        0.42738334,  0.48042478,  0.26735206, -0.14045925, -0.09188146])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed[f'{column_name}.normalized'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0902761 ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.015343  ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.30312498,  0.        ,  0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.26735206,  0.        ,  0.        ,  0.        ],\n",
       "       [-0.14045925,  0.        ,  0.        ,  0.        ],\n",
       "       [-0.09188146,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[:, 0] = transformed[f'{column_name}.normalized'].to_numpy()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 2, 0, 2, 1, 1, 1, 2, 2, 1, 2, 0, 2, 1, 2, 1, 2, 1, 0, 0,\n",
       "       1, 2, 2, 1, 0, 0, 2, 1, 1, 2, 2, 1, 1, 1, 2, 0, 1, 1, 2, 1, 2, 2,\n",
       "       1, 2, 0, 2, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 2, 1, 1, 2, 2, 1, 2, 1,\n",
       "       1, 0, 1, 0, 1, 2, 2, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 2, 2, 1, 1,\n",
       "       0, 0, 1, 1, 0, 2, 1, 0, 2, 2, 0, 0, 1, 1, 0, 0, 1, 0, 2, 2, 1, 2,\n",
       "       2, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 0, 1, 2, 2, 2, 0, 1, 2, 1, 2,\n",
       "       2, 2, 1, 1, 0, 2, 1, 1, 1, 0, 0, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 1,\n",
       "       2, 0, 2, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 2, 1, 1, 0, 1,\n",
       "       2, 1, 1, 0, 1, 1, 1, 1, 2, 1, 0, 0, 1, 1, 0, 2, 2, 0, 2, 2, 0, 0,\n",
       "       2, 0, 0, 2, 0, 2, 2, 2, 1, 2, 2, 0, 0, 0, 1, 1, 2, 2, 2, 0, 1, 1,\n",
       "       1, 0, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 2,\n",
       "       0, 1, 0, 2, 2, 1, 0, 2, 2, 2, 0, 2, 2, 1, 1, 2, 0, 2, 0, 2, 2, 2,\n",
       "       2, 0, 1, 1, 2, 1, 1, 0, 1, 1, 1, 2, 2, 1, 2, 1, 2, 0, 0, 1, 1, 1,\n",
       "       2, 0, 2, 0, 2, 2, 1, 1, 2, 1, 1, 0, 0, 2, 0, 1, 1, 0, 1, 2, 2, 2,\n",
       "       1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2,\n",
       "       1, 2, 0, 0, 0, 2, 2, 2, 1, 2, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 0,\n",
       "       2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 0,\n",
       "       2, 1, 0, 1, 2, 1, 2, 2, 2, 1, 2, 0, 1, 0, 0, 0, 1, 2, 0, 2, 1, 1,\n",
       "       0, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 0, 0, 0,\n",
       "       2, 1, 2, 0, 0, 2, 2, 1, 1, 2, 2, 1, 0, 2, 2, 1, 0, 1, 2, 1, 2, 1,\n",
       "       2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 0, 0, 2, 2, 2, 0, 1, 1, 1, 2, 1,\n",
       "       1, 2, 2, 1, 1, 1, 0, 2, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 2, 2, 1, 1,\n",
       "       2, 1, 1, 2, 1, 0, 1, 1, 2, 2, 2, 1, 2, 0, 1, 1, 2, 2, 0, 0, 2, 0,\n",
       "       2, 1, 1, 1, 2, 0, 2, 2, 1, 2, 0, 1, 2, 0, 2, 2, 0, 1, 1, 1, 0, 1,\n",
       "       2, 1, 0, 0, 2, 1, 0, 0, 0, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 2,\n",
       "       1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 0, 0, 0, 2, 1, 2, 0, 2, 2, 2,\n",
       "       1, 0, 0, 0, 1, 2, 2, 2, 1, 0, 2, 2, 2, 0, 1, 2, 1, 2, 1, 2, 0, 1,\n",
       "       2, 2, 1, 2, 2, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 2, 2, 1, 0, 0, 0,\n",
       "       2, 2, 1, 0, 2, 1, 1, 2, 1, 2, 0, 2, 0, 1, 1, 1, 2, 1, 0, 1, 2, 1,\n",
       "       2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 0, 0, 1, 0, 1, 2, 2, 0,\n",
       "       0, 2, 2, 2, 0, 1, 2, 2, 2, 1, 0, 1, 0, 0, 2, 2, 0, 1, 1, 2, 0, 2,\n",
       "       2, 1, 1, 2, 1, 2, 2, 0, 2, 2, 1, 2, 2, 1, 1, 0, 1, 0, 1, 0, 2, 2,\n",
       "       0, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 2, 1, 0, 1, 2, 1, 1, 2, 2, 2, 1,\n",
       "       1, 1, 0, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1,\n",
       "       2, 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 1, 0, 0, 2, 1, 1, 2, 1, 2, 0, 2,\n",
       "       2, 2, 2, 2, 1, 2, 1, 0, 1, 2, 2, 1, 0, 2, 1, 1, 1, 1, 2, 0, 1, 0,\n",
       "       1, 2, 2, 1, 0, 2, 0, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 2, 0, 2, 2, 2, 2, 1, 1, 0, 1, 2, 2, 2, 2, 2, 2, 1,\n",
       "       2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 0, 2, 2, 2, 2, 0, 1, 2, 1,\n",
       "       2, 2, 1, 0, 1, 1, 2, 0, 1, 2, 1, 2, 0, 0, 0, 1, 0, 1, 0, 0, 2, 2,\n",
       "       2, 1, 1, 2, 2, 1, 0, 2, 2, 1, 2, 2, 1, 0, 0, 1, 1, 1, 2, 2, 0, 1,\n",
       "       2, 0, 2, 2, 0, 1, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 0, 1, 0, 1, 2, 1,\n",
       "       2, 2, 1, 1, 0, 2, 1, 0, 2, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 2, 2,\n",
       "       2, 0, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 0, 1, 2, 1, 1, 1, 2,\n",
       "       2, 0, 2, 2, 0, 1, 1, 2, 2, 0])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = transformed[f'{column_name}.component'].to_numpy().astype(int)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0902761 ,  0.        ,  0.        ,  1.        ],\n",
       "       [ 0.015343  ,  1.        ,  0.        ,  0.        ],\n",
       "       [ 0.30312498,  0.        ,  0.        ,  1.        ],\n",
       "       ...,\n",
       "       [ 0.26735206,  0.        ,  0.        ,  1.        ],\n",
       "       [-0.14045925,  0.        ,  0.        ,  1.        ],\n",
       "       [-0.09188146,  1.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[np.arange(index.size), index + 1] = 1.0\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _transform_discrete(column_transform_info, data):\n",
    "    ohe = column_transform_info.transform\n",
    "    return ohe.transform(data).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auto_make</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mercedes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dodge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chevrolet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Honda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Volkswagen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Suburu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Audi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Mercedes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      auto_make\n",
       "0          Saab\n",
       "1      Mercedes\n",
       "2         Dodge\n",
       "3     Chevrolet\n",
       "4        Accura\n",
       "..          ...\n",
       "995       Honda\n",
       "996  Volkswagen\n",
       "997      Suburu\n",
       "998        Audi\n",
       "999    Mercedes\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_transform_info = column_transform_info_list[3]\n",
    "column_name = column_transform_info.column_name\n",
    "data = raw_data[[column_name]]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = column_transform_info.transform\n",
    "ohe.transform(data).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _synchronous_transform(raw_data, column_transform_info_list):\n",
    "        \"\"\"Take a Pandas DataFrame and transform columns synchronous.\n",
    "        Outputs a list with Numpy arrays.\n",
    "        \"\"\"\n",
    "        column_data_list = []\n",
    "        for column_transform_info in column_transform_info_list:\n",
    "            column_name = column_transform_info.column_name\n",
    "            data = raw_data[[column_name]]\n",
    "            if column_transform_info.column_type == 'continuous':\n",
    "                column_data_list.append(_transform_continuous(column_transform_info, data))\n",
    "            else:\n",
    "                column_data_list.append(_transform_discrete(column_transform_info, data))\n",
    "\n",
    "        return column_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_data_list = []\n",
    "for column_transform_info in column_transform_info_list:\n",
    "    column_name = column_transform_info.column_name\n",
    "    data = raw_data[[column_name]]\n",
    "    if column_transform_info.column_type == 'continuous':\n",
    "        column_data_list.append(_transform_continuous(column_transform_info, data))\n",
    "    else:\n",
    "        column_data_list.append(_transform_discrete(column_transform_info, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.0902761 ,  0.        ,  0.        ,  1.        ],\n",
       "        [ 0.015343  ,  1.        ,  0.        ,  0.        ],\n",
       "        [ 0.30312498,  0.        ,  0.        ,  1.        ],\n",
       "        ...,\n",
       "        [ 0.26735206,  0.        ,  0.        ,  1.        ],\n",
       "        [-0.14045925,  0.        ,  0.        ,  1.        ],\n",
       "        [-0.09188146,  1.        ,  0.        ,  0.        ]]),\n",
       " array([[ 0.14012159,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.0108117 ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [-0.41557301,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "          0.        ],\n",
       "        ...,\n",
       "        [ 0.28285664,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [-0.1534227 ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.05825112,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ]]),\n",
       " array([[ 0.18047708,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [-0.04976594,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [-0.52980338,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        ...,\n",
       "        [ 0.03827376,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "          0.        ],\n",
       "        [-0.20039795,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [-0.03662356,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ]]),\n",
       " array([[1, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0]]),\n",
       " array([[1, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0]]),\n",
       " array([[1, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 1, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0]])]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(raw_data):\n",
    "    \"\"\"Take raw data and output a matrix data.\"\"\"\n",
    "    column_data_list = _synchronous_transform(raw_data, _column_transform_info_list)\n",
    "    return np.concatenate(column_data_list, axis=1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 90)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_data_list = _synchronous_transform(raw_data, column_transform_info_list)\n",
    "output_of_transform = np.concatenate(column_data_list, axis=1).astype(float)\n",
    "output_of_transform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0902761 ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.015343  ,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.30312498,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.26735206,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.14045925,  0.        ,  0.        , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.09188146,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_of_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[SpanInfo(dim=1, activation_fn='tanh'),\n",
       "  SpanInfo(dim=3, activation_fn='softmax')],\n",
       " [SpanInfo(dim=1, activation_fn='tanh'),\n",
       "  SpanInfo(dim=5, activation_fn='softmax')],\n",
       " [SpanInfo(dim=1, activation_fn='tanh'),\n",
       "  SpanInfo(dim=5, activation_fn='softmax')],\n",
       " [SpanInfo(dim=14, activation_fn='softmax')],\n",
       " [SpanInfo(dim=39, activation_fn='softmax')],\n",
       " [SpanInfo(dim=21, activation_fn='softmax')]]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_discrete_column(column_info):\n",
    "    return (len(column_info) == 1 and column_info[0].activation_fn == 'softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[SpanInfo(dim=1, activation_fn='tanh'),\n",
       "  SpanInfo(dim=3, activation_fn='softmax')],\n",
       " [SpanInfo(dim=1, activation_fn='tanh'),\n",
       "  SpanInfo(dim=5, activation_fn='softmax')],\n",
       " [SpanInfo(dim=1, activation_fn='tanh'),\n",
       "  SpanInfo(dim=5, activation_fn='softmax')],\n",
       " [SpanInfo(dim=14, activation_fn='softmax')],\n",
       " [SpanInfo(dim=39, activation_fn='softmax')],\n",
       " [SpanInfo(dim=21, activation_fn='softmax')]]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = output_of_transform\n",
    "output_info = output_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   5,   9,  12,  58,  78,  90,  98, 100, 101, 106, 108, 113,\n",
       "       129, 154, 157, 167, 195, 204, 218, 228, 238, 240, 246, 252, 276,\n",
       "       338, 359, 362, 370, 390, 392, 398, 431, 463, 476, 477, 492, 499,\n",
       "       542, 554, 558, 565, 577, 589, 598, 599, 619, 623, 636, 642, 663,\n",
       "       676, 677, 683, 686, 687, 689, 699, 712, 732, 758, 773, 794, 805,\n",
       "       809, 841, 849, 854, 876, 877, 891, 895, 896, 899, 904, 907, 930,\n",
       "       959, 979])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = 16\n",
    "j=0\n",
    "np.nonzero(data[:, st + j])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* for each discrete column we construct `rid_by_cat` list. so in this example we construct three `rid_by_cat` list, and add these three lists to `_rid_by_cat_cols` list. Each `rid_by_cat` contains a number of lists, one list for each category in the related discrete column. In each list we have the row ids that the value of discrete column is equal to the related category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the row id for each category in each discrete column.\n",
    "# For example _rid_by_cat_cols[a][b] is a list of all rows with the\n",
    "# a-th discrete column equal value b.\n",
    "_rid_by_cat_cols = []\n",
    "\n",
    "# Compute _rid_by_cat_cols\n",
    "st = 0\n",
    "for column_info in output_info:\n",
    "    if is_discrete_column(column_info):\n",
    "        span_info = column_info[0]\n",
    "        ed = st + span_info.dim\n",
    "\n",
    "        rid_by_cat = []\n",
    "        for j in range(span_info.dim):\n",
    "            rid_by_cat.append(np.nonzero(data[:, st + j])[0])\n",
    "        _rid_by_cat_cols.append(rid_by_cat)\n",
    "        st = ed\n",
    "    else:\n",
    "        st += sum([span_info.dim for span_info in column_info])\n",
    "assert st == data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_rid_by_cat_cols[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare an interval matrix for efficiently sample conditional vector\n",
    "max_category = max([ column_info[0].dim for column_info in output_info if is_discrete_column(column_info)], default=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_discrete_columns = sum([1 for column_info in output_info if is_discrete_column(column_info)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_discrete_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "_discrete_column_cond_st = np.zeros(n_discrete_columns, dtype='int32')\n",
    "_discrete_column_n_category = np.zeros(n_discrete_columns, dtype='int32')\n",
    "_discrete_column_category_prob = np.zeros((n_discrete_columns, max_category))\n",
    "_n_discrete_columns = n_discrete_columns\n",
    "_n_categories = sum([column_info[0].dim for column_info in output_info if is_discrete_column(column_info)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_n_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_frequency = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_freq = np.sum(data[:, 30:69], axis=0)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000.0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(category_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = 0\n",
    "current_id = 0\n",
    "current_cond_st = 0\n",
    "for column_info in output_info:\n",
    "    if is_discrete_column(column_info):\n",
    "        span_info = column_info[0]\n",
    "        ed = st + span_info.dim\n",
    "        category_freq = np.sum(data[:, st:ed], axis=0)\n",
    "        if log_frequency:\n",
    "            category_freq = np.log(category_freq + 1)\n",
    "        category_prob = category_freq / np.sum(category_freq)\n",
    "        _discrete_column_category_prob[current_id, :span_info.dim] = category_prob\n",
    "        _discrete_column_cond_st[current_id] = current_cond_st\n",
    "        _discrete_column_n_category[current_id] = span_info.dim\n",
    "        current_cond_st += span_info.dim\n",
    "        current_id += 1\n",
    "        st = ed\n",
    "    else:\n",
    "        st += sum([span_info.dim for span_info in column_info])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0733736 , 0.06995417, 0.0733736 , 0.07252801, 0.07069638,\n",
       "        0.07295615, 0.07093662, 0.07117346, 0.07163729, 0.0733736 ,\n",
       "        0.07163729, 0.07045262, 0.06721082, 0.07069638, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.02662307, 0.02634563, 0.02991919, 0.02544961, 0.02027943,\n",
       "        0.02634563, 0.02740138, 0.02764467, 0.02662307, 0.02634563,\n",
       "        0.02876009, 0.02479037, 0.02876009, 0.02854924, 0.02544961,\n",
       "        0.02764467, 0.02407111, 0.02407111, 0.02662307, 0.02544961,\n",
       "        0.02407111, 0.02327981, 0.02327981, 0.02973743, 0.0219211 ,\n",
       "        0.02512686, 0.02479037, 0.0278807 , 0.02479037, 0.02407111,\n",
       "        0.02575971, 0.02086535, 0.02240042, 0.02715036, 0.02443891,\n",
       "        0.02833261, 0.02407111, 0.02512686, 0.02575971],\n",
       "       [0.04530002, 0.04875581, 0.04674642, 0.04828344, 0.0485219 ,\n",
       "        0.04728042, 0.04753896, 0.04467013, 0.04804026, 0.04898536,\n",
       "        0.04618813, 0.04828344, 0.04943196, 0.04898536, 0.04921069,\n",
       "        0.04701632, 0.04964931, 0.04618813, 0.04560325, 0.04728042,\n",
       "        0.04804026, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_discrete_column_category_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 14, 53], dtype=int32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " _discrete_column_cond_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 39, 21], dtype=int32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " _discrete_column_n_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _random_choice_prob_index(self, discrete_column_id):\n",
    "    probs = self._discrete_column_category_prob[discrete_column_id]\n",
    "    r = np.expand_dims(np.random.rand(probs.shape[0]), axis=1)\n",
    "    return (probs.cumsum(axis=1) > r).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 0, 1])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is discrete_column_id in the function _random_choice_prob_index?\n",
    "batch = 5\n",
    "discrete_column_id = np.random.choice(np.arange(_n_discrete_columns), batch)\n",
    "discrete_column_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04530002, 0.04875581, 0.04674642, 0.04828344, 0.0485219 ,\n",
       "        0.04728042, 0.04753896, 0.04467013, 0.04804026, 0.04898536,\n",
       "        0.04618813, 0.04828344, 0.04943196, 0.04898536, 0.04921069,\n",
       "        0.04701632, 0.04964931, 0.04618813, 0.04560325, 0.04728042,\n",
       "        0.04804026, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.02662307, 0.02634563, 0.02991919, 0.02544961, 0.02027943,\n",
       "        0.02634563, 0.02740138, 0.02764467, 0.02662307, 0.02634563,\n",
       "        0.02876009, 0.02479037, 0.02876009, 0.02854924, 0.02544961,\n",
       "        0.02764467, 0.02407111, 0.02407111, 0.02662307, 0.02544961,\n",
       "        0.02407111, 0.02327981, 0.02327981, 0.02973743, 0.0219211 ,\n",
       "        0.02512686, 0.02479037, 0.0278807 , 0.02479037, 0.02407111,\n",
       "        0.02575971, 0.02086535, 0.02240042, 0.02715036, 0.02443891,\n",
       "        0.02833261, 0.02407111, 0.02512686, 0.02575971],\n",
       "       [0.04530002, 0.04875581, 0.04674642, 0.04828344, 0.0485219 ,\n",
       "        0.04728042, 0.04753896, 0.04467013, 0.04804026, 0.04898536,\n",
       "        0.04618813, 0.04828344, 0.04943196, 0.04898536, 0.04921069,\n",
       "        0.04701632, 0.04964931, 0.04618813, 0.04560325, 0.04728042,\n",
       "        0.04804026, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.0733736 , 0.06995417, 0.0733736 , 0.07252801, 0.07069638,\n",
       "        0.07295615, 0.07093662, 0.07117346, 0.07163729, 0.0733736 ,\n",
       "        0.07163729, 0.07045262, 0.06721082, 0.07069638, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.02662307, 0.02634563, 0.02991919, 0.02544961, 0.02027943,\n",
       "        0.02634563, 0.02740138, 0.02764467, 0.02662307, 0.02634563,\n",
       "        0.02876009, 0.02479037, 0.02876009, 0.02854924, 0.02544961,\n",
       "        0.02764467, 0.02407111, 0.02407111, 0.02662307, 0.02544961,\n",
       "        0.02407111, 0.02327981, 0.02327981, 0.02973743, 0.0219211 ,\n",
       "        0.02512686, 0.02479037, 0.0278807 , 0.02479037, 0.02407111,\n",
       "        0.02575971, 0.02086535, 0.02240042, 0.02715036, 0.02443891,\n",
       "        0.02833261, 0.02407111, 0.02512686, 0.02575971]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = _discrete_column_category_prob[discrete_column_id]\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 39)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73525242, 0.89662611, 0.40810784, 0.04870378, 0.47171214])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(probs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.79121127],\n",
       "       [0.01022469],\n",
       "       [0.11835301],\n",
       "       [0.52365145],\n",
       "       [0.48105196]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.expand_dims(np.random.rand(probs.shape[0]), axis=1)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True],\n",
       "       [False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True],\n",
       "       [False, False, False, False, False, False, False,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.cumsum(axis=1) > r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30,  0,  1,  7, 18])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(probs.cumsum(axis=1) > r).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = np.zeros((batch, _n_categories), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30,  0,  1,  7, 18])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_id_in_col = (probs.cumsum(axis=1) > r).argmax(axis=1)\n",
    "category_id_in_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44,  0,  1,  7, 32])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_id = (_discrete_column_cond_st[discrete_column_id] + category_id_in_col)\n",
    "category_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond[np.arange(batch), category_id] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 74)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.zeros((batch, _n_discrete_columns), dtype='float32')\n",
    "mask[np.arange(batch), discrete_column_id] = 1\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 0, 0, 1]), array([30,  0,  1,  7, 18]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrete_column_id, category_id_in_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = np.arange(batch)\n",
    "np.random.shuffle(perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[SpanInfo(dim=1, activation_fn='tanh'),\n",
       "  SpanInfo(dim=3, activation_fn='softmax')],\n",
       " [SpanInfo(dim=1, activation_fn='tanh'),\n",
       "  SpanInfo(dim=5, activation_fn='softmax')],\n",
       " [SpanInfo(dim=1, activation_fn='tanh'),\n",
       "  SpanInfo(dim=5, activation_fn='softmax')],\n",
       " [SpanInfo(dim=14, activation_fn='softmax')],\n",
       " [SpanInfo(dim=39, activation_fn='softmax')],\n",
       " [SpanInfo(dim=21, activation_fn='softmax')]]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(self, data, c, m, output_info):\n",
    "        \"\"\"Compute the cross entropy loss on the fixed discrete column.\"\"\"\n",
    "        loss = []\n",
    "        st = 0\n",
    "        st_c = 0\n",
    "        for column_info in output_info:\n",
    "            for span_info in column_info:\n",
    "                if len(column_info) != 1 or span_info.activation_fn != 'softmax':\n",
    "                    # not discrete column\n",
    "                    st += span_info.dim\n",
    "                else:\n",
    "                    ed = st + span_info.dim\n",
    "                    ed_c = st_c + span_info.dim\n",
    "                    labels=tf.math.argmax(c[:, st_c:ed_c], 1)\n",
    "                    labels = tf.reshape(labels, [-1,1])\n",
    "                    logits=data[:, st:ed]\n",
    "                    tmp = tf.nn.softmax_cross_entropy_with_logits(\n",
    "                        labels,\n",
    "                        logits)\n",
    "                    loss.append(tmp)\n",
    "                    st = ed\n",
    "                    st_c = ed_c\n",
    "\n",
    "        loss = tf.stack(loss, axis=1)\n",
    "        m1 = tf.cast(m, dtype=tf.float32)\n",
    "        return tf.reduce_mean(loss * m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generator loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 15:32:52.137887: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from data_transformer import DataTransformer\n",
    "from data_sampler import DataSampler\n",
    "from ctgan import CTGAN\n",
    "\n",
    "import pandas as pd\n",
    "with tf.device('/gpu:1'):\n",
    "   \n",
    "     df = pd.read_csv('insurance_claims.csv')\n",
    "     raw_data = df[['injury_claim', 'property_claim', 'vehicle_claim', 'auto_make', 'auto_model', 'auto_year']]\n",
    "\n",
    "     transformer = DataTransformer()\n",
    "     transformer.fit(raw_data, discrete_columns=('auto_make', 'auto_model', 'auto_year'))\n",
    "     data_t = transformer.transform(raw_data)      #matrix of transformed data\n",
    "     output_info = transformer.output_info_list\n",
    "\n",
    "     log_frequency = True\n",
    "     sampler = DataSampler(data_t, output_info, log_frequency)\n",
    "\n",
    "     model = CTGAN()\n",
    "\n",
    "     generator  = model.make_generator(sampler, transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 15:37:20.932327: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-04-19 15:37:21.833424: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-04-19 15:37:21.834245: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-04-19 15:37:21.858890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.45GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-04-19 15:37:21.859163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:af:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.45GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-04-19 15:37:21.859180: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-04-19 15:37:21.860787: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-04-19 15:37:21.860820: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-04-19 15:37:21.862197: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-04-19 15:37:21.862416: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-04-19 15:37:21.863975: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-04-19 15:37:21.864779: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-04-19 15:37:21.868046: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-04-19 15:37:21.868732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2023-04-19 15:37:21.869023: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-19 15:37:21.870262: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-04-19 15:37:22.020418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.45GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-04-19 15:37:22.020902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:af:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.45GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-04-19 15:37:22.020925: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-04-19 15:37:22.020950: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-04-19 15:37:22.020957: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-04-19 15:37:22.020964: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-04-19 15:37:22.020971: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-04-19 15:37:22.020977: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-04-19 15:37:22.020984: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-04-19 15:37:22.020992: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-04-19 15:37:22.021494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2023-04-19 15:37:22.021517: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-04-19 15:37:22.740386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-04-19 15:37:22.740416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2023-04-19 15:37:22.740420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y \n",
      "2023-04-19 15:37:22.740423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N \n",
      "2023-04-19 15:37:22.741187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1664 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:3b:00.0, compute capability: 7.5)\n",
      "2023-04-19 15:37:22.741833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 44421 MB memory) -> physical GPU (device: 1, name: Quadro RTX 8000, pci bus id: 0000:af:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sampler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2666443/424573760.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0membedding_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfakez\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcondvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_condvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcondvec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sampler' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "batch_size = 5\n",
    "embedding_dim = 128\n",
    "fakez = tf.random.normal(shape=(batch_size, embedding_dim), mean= 0, stddev= 1)\n",
    "condvec = sampler.sample_condvec(batch_size)\n",
    "\n",
    "c1, m1, col, opt = condvec\n",
    "c1 = tf.convert_to_tensor(np.array(c1))\n",
    "c1 = tf.cast(c1, dtype=tf.float32)\n",
    "\n",
    "m1 = tf.convert_to_tensor(np.array(m1))\n",
    "m1 = tf.cast(m1, dtype=tf.int32)\n",
    "\n",
    "fakez = tf.concat([fakez, c1], axis=1)\n",
    "\n",
    "fake = generator(fakez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "condvec = sampler.sample_condvec(batch_size)\n",
    "c1, m1, col, opt = condvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = c1[:, 0:14]\n",
    "logits=fake[:, 16:30]\n",
    "tmp = tf.nn.softmax_cross_entropy_with_logits(labels,logits)\n",
    "loss.append(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0.      , 3.166882, 0.      , 0.      , 0.      ], dtype=float32)>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = c1[:, 14:53]\n",
    "logits=fake[:, 30:69]\n",
    "tmp = tf.nn.softmax_cross_entropy_with_logits(labels,logits)\n",
    "loss.append(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = c1[:, 53:74]\n",
    "logits=fake[:, 69:90]\n",
    "tmp = tf.nn.softmax_cross_entropy_with_logits(labels,logits)\n",
    "loss.append(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
       "array([2.6690714, 0.       , 2.6825294, 2.8406324, 3.0264661],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0.      , 3.166882, 0.      , 0.      , 0.      ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
       " array([2.6690714, 0.       , 2.6825294, 2.8406324, 3.0264661],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
       "array([[0.       , 0.       , 2.6690714],\n",
       "       [3.166882 , 0.       , 0.       ],\n",
       "       [0.       , 0.       , 2.6825294],\n",
       "       [0.       , 0.       , 2.8406324],\n",
       "       [0.       , 0.       , 3.0264661]], dtype=float32)>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = tf.stack(loss, axis=1)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
       "array([[   0.     ,    0.     ,  521.37866],\n",
       "       [ 303.00626,    0.     ,    0.     ],\n",
       "       [   0.     ,    0.     ,  781.2013 ],\n",
       "       [   0.     ,    0.     ,  707.9749 ],\n",
       "       [   0.     ,    0.     , 1028.0239 ]], dtype=float32)>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss *m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=222.77232>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(loss * m1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainenv",
   "language": "python",
   "name": "mainenv"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
